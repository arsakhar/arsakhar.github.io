[{"authors":["admin"],"categories":null,"content":"I am an academic researcher with a passion for problem solving and innovation in healthcare. I am currently utilizing novel MRI imaging techniques to elucidate the etiology of Alzheimer\u0026rsquo;s disease. As an extension of this work, I am also developing a virtual reality game to remediate cognitive decline in older adults. I have expertise in brain imaging, virtual reality, game development, and data science. I am a collaborative researcher who excels in multi-disciplinary environments.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://arsakhar.github.io/author/ashwin-sakhare/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/ashwin-sakhare/","section":"authors","summary":"I am an academic researcher with a passion for problem solving and innovation in healthcare. I am currently utilizing novel MRI imaging techniques to elucidate the etiology of Alzheimer\u0026rsquo;s disease. As an extension of this work, I am also developing a virtual reality game to remediate cognitive decline in older adults.","tags":null,"title":"Ashwin Sakhare","type":"authors"},{"authors":[],"categories":["Virtual Reality"],"content":"Background In a recent blog post (Locomotion in VR), I detailed some of the current technology that exists for locomotion in VR. Until recently, VirZoom was the only virtual reality bike on the market. However, at CES 2019, Nordic Track announced the release of their VR bike. This is great news for VR as many of the bigger companies are starting to see the value of VR in exercise and entertainment. The target audience for both VR bikes are generally younger to middle aged adults with a focus on entertainment, exercise, and gaming.\nIn our academic research lab, we focus on the applications of VR to rehabilitation in an older adult population. At the time of our VR biking study in older adults, the Nordic Track VR bike did not exist. While the VirZoom bike was a possibility, we did have several concerns. Turning in VR with the VirZoom bike is achieved by leaning one\u0026rsquo;s body in the intended direction of movement. VirZoom claims that this is a more natural method of turning that minimizes motion sickness and improves user safety while riding the VR bike.\nWhen we tried the VirZoom bike in our lab, our initial impressions were that it was a bit unnatural. While it\u0026rsquo;s possible that users would adjust to this over time, we thought the older adult population might do better on a bike with a turning mechanism that more closely resembled that of an actual bike. Furthermore, we hypothesized that requiring older adults to lean might introduce an additional safety risk, particularly in those with poor postural stability.\nObjective Our objective was to develop a custom bike that would allow for turning in VR by the same mechanism of a regular bike, rotating the handlebar clockwise or counter-clockwise. Moreover, we wanted our design to include digital control of the pedal resistance. This would allow for real-time manipulation of pedal resistance when participants were going up or down hills in a VR environment or as a means to increase a participants exertion during exercise.\nDesign Requirements The primary design requirements for our custom bike were stability, comfort, and ease of access for older adults. The bike was required to accommodate adults of different heights, trunk, leg, and arm lengths, and the turning and braking mechanisms for our bike were to be similar to that of a road bike. Furthermore, the bike was to be designed such that the pedal resistance could be manipulated from the computer in real-time. Finally, the bike should be able to interface with a computer and provide speed, turning, temperature, and braking feedback.\nMechanical Design The first step in the design process was to create a model of the bike using SolidWorks, a 3D CAD software. We then had the bike fabricated at our University's (USC) machine shop. The drivetrain, handlebar, and seat post frames were welded and constructed out of aluminum to reduce weight and cost. All other components, including the leg stabilizers and gearing mechanism within the drive train were bolt-mounted for ease of assembly/disassembly. The bike was comprised of adjustable angled telescopic seat and handlebar posts. The handlebar was mounted to a ball-bearing to allow approximately 150 degrees rotation. A brass set screw was used to manually adjust the resistance to turning. The bike consisted of a double gear reduction such that the output torque was approximately 11.5% of the input torque. A freewheel sprocket was used to allow for coasting. Radially oriented electromagnets were mounted concentrically inside a flywheel to allow for varying of pedal resistance using the principles of eddy current braking.\nElectrical Design Speed Detection\nSpeed detection was achieved using a custom laser-cut acrylic encoder wheel and Omron EE-SV3-D transmissive optical sensor. The optical sensor consisted of a photodiode (light emitter) and phototransistor (light detector). A standard 220 Ω resistor was connected in series between the 5V supply voltage and anode to keep the forward current within its specified current rating. The phototransistor was configured as a common collector (CC) phototransistor circuit. A 10 kΩ load resistor was added between ground and the emitter to configure the phototransistor for switch mode (), where the output was either OFF or ON based on the absence or presence of light, respectively. It should be noted that a 5 kΩ load resistor is typically adequate for switch mode and will have a faster response time to changes in light intensity compared to a 10 kΩ load resistor. The output signal from the collector was connected to a digital pin on the Arduino.\nTurning and Brake Sensing\nA linear, rotatory 10 kΩ potentiometer and dual-axis XY joystick module were used for turning and brake sensing, respectively. Both sensors were configured as voltage dividers, outputting a voltage between 0V and the 5V supply voltage based on the rotation of the knob or the deflection of the joystick.\nTemperature Sensor\nA TMP36 semi-conductor temperature sensor was used to monitor heat dissipation at the electromagnet coils. A 100 nF capacitor was added between the output pin and ground for each sensor to dampen signal fluctuations due to mechanical bounce, electrical noise, and electromagnetic interference. The output pin on each sensor was connected to a unique analog pin on the Arduino.\nPedal Resistance\nPulse width modulation (PWM) and a RFP30N06LE MOSFET transistor were used to manipulate pedal resistance. An HCPL-7710 opto-isolator was placed between the Arduino’s digital PWM signal and the MOSFET to electrically isolate the MOSFET from the Arduino. Indeed, the high PWM signal frequency (490 Hz) resulted in frequent switching of the MOSFET which caused undesirable noise during signal sampling. The PWM signal was connected to pin 2 of the opto-isolator. Arduino’s 5V power supply and ground were connected to pins 1 and 4 of the opto-isolator. 12V from an external variable power supply was regulated down to 5V via a L7805ABV linear voltage regulator and connected to pin 5 of the opto-isolator. Pin 8 of the opto-isolator was connected to ground of the external power supply. A 100 nF capacitor was connected between pins 1 and 4 and 5 and 8 of the opto-isolator in accordance with datasheet recommendations. Similarly, a 330 nF and 100 nF capacitor were connected between ground and the voltage regulator input and output pins, respectively.\nThe opto-isolated PWM signal at pin 6 of the opto-isolator was connected to the gate pin on the MOSFET. A 47 Ω gate resistor was placed in series with pin 6 of the opto-isolator and the MOSFET gate to limited ringing and electrical noise due to parasitic inductance. A 10 kΩ pull-down resistor was connected in series between ground and the MOSFET gate to pull the voltage down and turn the MOSFET off in the absence of a PWM input signal. The MOSFET source was connected to the source of the MOSFET. One electromagnet lead was connected to the source of the MOSFET, while the other was connected to 12V power from the external power supply. An 1N5817 Schottky diode was connected in parallel with the leads of the electromagnet to prevent flyback when current to the electromagnet is interrupted. A 2000 µF electrolytic capacitor and 100 nF capacitor were connected in parallel across 12V power and ground from the external power supply to smooth out the input voltage to the electromagnet.\nArduino Programming The temperature, turning, and braking sensors were connected to analog input pins, the speed sensor was connected to a digital input pin, and pedal resistance was provided by a PWM output pin on the Arduino Uno. The Arduino Uno connected to the PC via a USB A-Male to B-Male cable. A standard Arduino Uno driver was used to establish the connection as a COM port on the PC. The baud rate was set to 1,000,000 for serial port communication.\nThe ResponsiveAnalogRead library was used to reduce noise associated with the analog input signals for the brake, turning, and temperature sensors. All analog sensor values were updated within the main loop. For the speed sensor, an interrupt trigger was used to track when the state of the optical sensor changed. A digital pin reads HIGH(1) when the voltage signal is \u0026gt; 3.0V and LOW(0) when the voltage is \u0026lt; 3.0V on a 5V Arduino board.\nWhen determining speed, the Arduino code is structured to count the number of times the digital interrupt is triggered over a specified sampling period of 50ms. A digital interrupt is triggered when the encoder wheel spoke enters and leaves the light path. The number of interrupts over this 50 ms period is then converted to a speed using the following formula:\nInterrupt Count (counts/s) = Interrupt Count * (1 / 50 ms) * (1 / 1000s) Speed (m/s) = (2 * pi * Flywheel Radius (m)) / (Spokes per Revolution) * (Interrupt Count)\nNote: In practice, an additional fudge factor may be necessary to get the perceived pedal speed to correctly match the speed at which the user moves through the virtual environment\nEncoder Wheel\nThe encoder wheel was mounted to the output shaft of the flywheel and centered within the gap of the optical sensor. For the encoder wheels, we laser cut 6 different variations out of acrylic. These variations included 2, 4, 8, 16, 32, 64, and 128 spokes. For each wheel, we evaluated 2 conditions: aliasing and a ceiling effect. Aliasing occurs when the encoder wheel rotates faster than the optical sensor can react to the light change or the Arduino can trigger the digital interrupt pin. With a 10K load resistor, the response time of the phototransistor is approximately 100 µs. With the Arduino, the interrupt service routine theoretically executes every .625 µS based on a clock speed of 16 MHz.\nHowever, in practice, this is often much slower due to factors such as code overhead and often results in an interrupt frequency on the scale of milliseconds, which likely makes it the rate limiting step. The ceiling effect occurs when the resolution of the encoder wheel is too small to capture the actual pedal speed. In other words, after a certain pedal speed, the number of spokes that pass through the optical sensor gets capped over a 50 ms period. During testing, we found that the 2,4,8, and 16 spoke encoder wheels experienced the ceiling effect while the 128 spoke encoder wheel had significant aliasing at normal pedal speeds. We found the 64 spoke encoder wheel to be the best option as we found no aliasing and no ceiling effect, even at very high pedal speeds.\nAcknowledgements The bike design was a team effort with significant contributions from Roshan Ravichandran (lead mechanical design) and Delian Delev (lead electrical design). Additional design support was provided by Chintan Raja and Vincent Yang. Electromagnet guidance was provided by Andrew Bushnell. Special thanks to Don Wiggins and the USC machine shop for manufacturing the bike.\n","date":1593407959,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593407959,"objectID":"8690f638ba509d441fe1a28d3cee0d83","permalink":"https://arsakhar.github.io/project/vr-bike/","publishdate":"2020-06-28T22:19:19-07:00","relpermalink":"/project/vr-bike/","section":"project","summary":"A novel, custom-built exercise bike designed for locomotion in VR","tags":["Virtual Reality"],"title":"NeuroRiderVR","type":"project"},{"authors":[],"categories":["Clinical Research"],"content":" Overview Skills   Overview FitViz is a monitoring client designed for fitness enthusiasts and gamers. It supports real-time visualization and tracking of health and fitness data sent from ANT+ devices. FitViz also provides networking capabilities allowing game developers to easily integrate ANT+ devices, such as bike trainers and heart rate monitors, into their own game.\nThe idea behind this project was to provide a standalone PC application that allowed me to interface with a Wahoo Kickr Snap bike trainer. In particular, I was interested in obtaining real-time measurements of speed and power from the Wahoo Kickr to be used as an input controller for a VR game.\nAbout ANT+ ANT+ is a wireless sensor network technology that allows you to moniter data broadcast from ANT+ capable devices. Fitness equipment, bike trainers, heart rate monitors, and blood pressure monitors are just a few of the many devices supported within the ANT+ ecosystem. Data broadcast from ANT+ devices is standardized based on the type of data being sent. ANT+ refers to a data type as a device profile. An ANT+ device can broadcast data associated with multiple device profiles. For example, the Wahoo Kickr Snap broadcasts bicycle power and fitness equipment data.\nFitViz can be downloaded at: https://github.com/arsakhar/FitViz\n Technical Skills \rANT+ Communication\rCommunicating with and reading sensor information from ANT+ devices\r\rExporting Data\rWriting data to UDP port\rSaving data to CSV\r\rVisualization\rDeveloping GUI\rDisplaying sensor values in real-time\r\r\rPackages \rPyQt5\rLibAnt\r\r    ","date":1591425169,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591425169,"objectID":"d568f436b9973f37dc6baba118158b0a","permalink":"https://arsakhar.github.io/project/fitviz/","publishdate":"2020-06-05T23:32:49-07:00","relpermalink":"/project/fitviz/","section":"project","summary":"ANT+ Health and Fitness Monitoring Client","tags":["Clinical Research"],"title":"FitViz","type":"project"},{"authors":[],"categories":["Brain Imaging"],"content":" Overview Skills   Overview NeuroFlow is an imaging tool that allows neuroscientists and clinicians to analyze cerebral flow dynamics in the brain. The continuous circulation of cerebrospinal fluid (CSF) and cerebral blood flow (CBF) is key to the health of our central nervous system. When CSF and CBF dynamics in the brain become dysregulated, pathophysiological states can occur. As such, cerebral flow dynamics may be an important biomarker for identifying meaningful alterations in neurological diseases.\nPhase-contrast MRI (PC-MRI) is a validated, non-invasive MRI imaging technique, allowing rapid measurements of CSF and CBF flow in the brain. NeuroFlow provides a user-friendly interface for neuroscientists and clinicians to analyze PC-MRI images and extract measurements associated with cerebral flow dynamics. Moreover, NeuroFlow provides numerous tools to help user\u0026rsquo;s quickly, accurately, and painlessly analyze flow data.\nVideo \r\rNeuroFlow can be downloaded at: https://github.com/arsakhar/NeuroFlow\n Technical Skills \rReading and Loading DICOMDIR\rStoring Patient, Study, Series, Sequence, and Image information entities of the DICOM data model in accordance with the NEMA DICOM standard.\r\rImage Segmentation\rProviding tools for users to segment and label ROI’s on an image\r\rVisualization\rDeveloping GUI\rDisplaying Graphs, Images, Tables, and DICOM Metadata\r\rImage Classification\rTraining a CNN to classify MRI scans according to anatomical level in the brain\r\r\rPackages \rPyQt5\rNumPy\rPandas\rPyQtGraph\rPIL\rCV2\rTorch\rTorchVision\rMatplotlib\rPydicom\r\r    ","date":1591425169,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591425169,"objectID":"03962b78743a6d34b18ceadbd7231921","permalink":"https://arsakhar.github.io/project/neuroflow/","publishdate":"2020-06-05T23:32:49-07:00","relpermalink":"/project/neuroflow/","section":"project","summary":"A brain imaging tool for analyzing cerebral flow dynamics","tags":["Brain Imaging"],"title":"NeuroFlow","type":"project"},{"authors":[],"categories":["Data Science"],"content":" Overview Skills   Background\n I’m an avid college football fan with a keen interest in data science. For my first dive into data science, I will use some basic statistics and data manipulation to evaluate coaching in college football. Defining the Problem\n Football is the crown jewel and breadwinner in any collegiate athletic department. A successful football program is not only a source of revenue for the university, it is also a powerful marketing tool, as studies have shown winning to be associated with increased donations, academic reputation, and lower acceptance rates. Therefore, it’s no surprise that coaches wield significant power and lofty salaries.\nCoaches also carry the burden of high expectations, poor job security, and an average tenure of only 3.8 years. While the decision to hire or fire a coach is a multi-factorial process, it is primarily driven by their record. Consequently, a coach’s value, particularly with donors and fans, is inextricably tied to their performance on the field.\nHowever, wins and losses are driven by several factors, many of which are outside a coach’s control, including conference affiliation, prestige, location, historical success, and financial investment from the university. As such, a coach’s record is not the most objective way to assess their value. In this project we will set out to define an approach for evaluating coaches while minimizing the impact of these confounding factors. Let\u0026rsquo;s get started!\nContinue reading on Medium: Using Data Science to Evaluate Recruiting and Player Development in College Football \nCode can be downloaded at: https://github.com/arsakhar/NCAAF\n Technical Skills \rData Visualization\rHistograms, scatterplots, qq plots, boxplots\r\rData Scraping\rScraping data across 4 different websites\r\rData Cleaning\rRemoving empty rows in dataframe\rRemoving non-numeric / nan rows in dataframe\rFiltering dataframe by a specific keyword or attribute\r\rData Manipulation\rJoining dataframes\rTransforming values on a dataframe column\rApplying a function elementwise on a dataframe column\rFiltering dataframe based on a specific attribute or keyword\rAggregating on a dataframe column (standard deviation, mean, min, max, sum, count)\r\rStatistical Analysis\rShapiro-Wilks test for normality\rKruskal-Wallis non-parametric test for group differences\rDunn post-hoc testing for pairwise comparisons\rBox-cox for transforming skewed distribution to a gaussian\r\r\rPackages \rBeautiful Soup\rScipy\rMatplotlib\rPandas\rNumpy\rScikit\rStatsModels\r\r    ","date":1591425169,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591425169,"objectID":"2d1e94261004d0b2bbd4f04dfd2fbfa4","permalink":"https://arsakhar.github.io/project/ncaaf-coaches/","publishdate":"2020-06-05T23:32:49-07:00","relpermalink":"/project/ncaaf-coaches/","section":"project","summary":"Using data science to evaluate recruiting and player development in college football","tags":["Data Science"],"title":"Ranking College Football Coaches","type":"project"},{"authors":[],"categories":["Virtual Reality"],"content":"Overview The first in a trilogy of virtual reality exergames designed to enhance brain health. Your adventure begins as a rookie ranger at Sal\u0026rsquo;s Sanctuary, a nature reserve for animals set in an urban environment. The animal\u0026rsquo;s have escaped the sanctuary and you are tasked with locating and returning them safely. Your selective attention and spatial navigation abilities will be tested each time you conduct a rescue mission.\nYou are assigned to one route each day and will be required to make at least 4 search and rescue trips along this route. Once an animal is located, you will pick it up and bring it back to the gates of the sanctuary before starting your next search and rescue. You are also required to pick up any food along the route that is associated with the diet of the animal you have rescued.\nFor the first two rescue missions, we will provide visual guidance to help you learn the route. After 2 rescue missions, you are required to remember the route using only the landmarks and environment as your guidance. At the beginning of each new day, prior to starting your 4 rescue missions, you will be required to remember and navigate the route from the previous day. The difficulty of your routes will increase and the routes will get longer as you start rescuing animals located farther away from the sanctuary.\nVideo \r\r","date":1591420759,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591420759,"objectID":"c108693625611d1a5a192c7e7cde9762","permalink":"https://arsakhar.github.io/project/sals-sanctuary/","publishdate":"2020-06-05T22:19:19-07:00","relpermalink":"/project/sals-sanctuary/","section":"project","summary":"Rescue animals that have escaped the sanctuary while navigating an urban environment","tags":["Virtual Reality"],"title":"Sal's Sanctuary","type":"project"},{"authors":[],"categories":["Virtual Reality"],"content":"Overview This is the third in our trilogy of virtual reality exergames. After conquering the land, you now turn your attention to the sea. Sal plans to build a marine sanctuary and he needs your help. On this adventure, you will take pictures and collect objects that will inspire the underwater sanctuary. You will start by exploring the island and collecting the equipment necessary to begin your descent into the ocean. Sal is planning on sending you pretty deep \u0026ndash; you didn\u0026rsquo;t hear it from me, but I heard he has some secret information on the lost city of Atlantis. We shouldn\u0026rsquo;t speculate, though.\nStay tuned for more to come\u0026hellip;\nVideo \r\r","date":1591416312,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591416312,"objectID":"62c232ea236e2cc8b2544de3520bf8d4","permalink":"https://arsakhar.github.io/project/underwater-adventures/","publishdate":"2020-06-05T21:05:12-07:00","relpermalink":"/project/underwater-adventures/","section":"project","summary":"Explore the underwater","tags":["Virtual Reality"],"title":"Underwater Adventures","type":"project"},{"authors":[],"categories":["Virtual Reality"],"content":"Overview This is the second in our trilogy of virtual reality exergames. You start the game as the chief ranger at Sal\u0026rsquo;s Wildlife Enclosure, a nature reserve for animals set in a savannah, jungle, safari, and aviary. You are tasked with taking care of all the animal\u0026rsquo;s in the wildlife enclosure. Your missions consist of feeding animals, treating injured animals at the vet clinic, putting out fires, and repairing broken equipment. There are two primary cognitive skills assessed each day you bike around the enclosure to complete your missions: selective attention and spatial navigation.\nFor the selective attention task, you are required to pick up objects associated with your mission. For example, if you are putting out a fire, you will be required to pickup axes and fire extinguishers on the way. For spatial navigation, you are assigned to one route each day. You will complete 4 missions, each time biking along the same route. For the first two missions, we will provide arrows to help you learn the route. After 2 missions, you are required to remember the route using only the landmarks and environment as cues. At the beginning of each day, prior to starting your 4 missions, you will be required to remember and navigate the route from the previous day. The difficulty of your routes will increase and the routes will get longer as you start moving towards the perimeter of the wildlife enclosure.\nVideo \r\r","date":1591416312,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591416312,"objectID":"47c95502e75899a34f6b2c4422a4b79f","permalink":"https://arsakhar.github.io/project/wildlife-enclosure/","publishdate":"2020-06-05T21:05:12-07:00","relpermalink":"/project/wildlife-enclosure/","section":"project","summary":"Look after and take care of rescued animals located in exotic environments","tags":["Virtual Reality"],"title":"Wildlife Enclosure","type":"project"},{"authors":["Ashwin Sakhare","Vincent Yang","Joy Stradford","Ivan Tsang","Roshan Ravichandran","Judy Pa"],"categories":[],"content":"","date":1590301229,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590301229,"objectID":"76cf319054d03143ed88e0b110e466dc","permalink":"https://arsakhar.github.io/publication/frontiers-aging-neuroscience/","publishdate":"2019-08-16T23:20:29-07:00","relpermalink":"/publication/frontiers-aging-neuroscience/","section":"publication","summary":"Background: Cognitive decline is a significant public health concern in older adults. Identifying new ways to maintain cognitive and brain health throughout the lifespan is of utmost importance. Simultaneous exercise and cognitive engagement has been shown to enhance brain function in animal and human studies. Virtual reality (VR) may be a promising approach for conducting simultaneous exercise and cognitive studies. In this study, we evaluated the feasibility of cycling in a cognitively enriched and immersive spatial navigation VR environment in younger and older adults. Methods: A total of 20 younger (25.9 ± 3.7 years) and 20 older (63.6 ± 5.6 years) adults participated in this study. Participants completed four trials (2 learning and 2 recall) of cycling while wearing a head-mounted device (HMD) and navigating a VR park environment. Questionnaires were administered to assess adverse effects, mood, presence, and physical exertion levels associated with cycling in the VR environment. Results: A total of 4 subjects withdrew from the study due to adverse effects, yielding a 90% completion rate. Simulator sickness levels were enhanced in both age groups with exposure to the VR environment but were within an acceptable range. Exposure to the virtual environment was associated with high arousal and low stress levels, suggesting a state of excitement, and most participants reported enjoyment of the spatial navigation task and VR environment. No association was found between physical exertion levels and simulator sickness levels. Conclusion: This study demonstrates that spatial navigation while cycling is feasible and that older adults report similar experiences to younger adults. VR may be a powerful tool for engaging physical and cognitive activity in older adults with acceptable adverse effects and with reports of enjoyment. Future studies are needed to assess the efficacy of a combined exercise and cognitive VR program as an intervention for promoting healthy brain aging, especially in older adults with increased risk of age-related cognitive decline.","tags":[],"title":"Cycling and Spatial Navigation in an Enriched, Immersive 3D Virtual Park Environment: A Feasibility Study in Younger and Older Adults","type":"publication"},{"authors":["Ashwin R Sakhare","Giuseppe Barisano","Judy Pa"],"categories":[],"content":"","date":1590300799,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590300799,"objectID":"499edcc241e806df2d9e53a416261f5c","permalink":"https://arsakhar.github.io/publication/magnetic-resonance-medicine/","publishdate":"2019-05-10T23:13:19-07:00","relpermalink":"/publication/magnetic-resonance-medicine/","section":"publication","summary":" Purpose: Pathological states occur when cerebrospinal fluid (CSF) and cerebral blood flow (CBF) dynamics become dysregulated in the brain. Phase‐contrast MRI (PC‐MRI) is a noninvasive imaging technique that enables quantitative measurements of CSF and CBF flow. While studies have validated PC‐MRI as an imaging technique for flow, few studies have evaluated its reliability for CSF and CBF flow parameters commonly associated with neurological disease. The purpose of this study was to evaluate test–retest reliability at the cerebral aqueduct (CA) and C2‐C3 area using PC‐MRI to assess the feasibility of investigating CSF and CBF flow dynamics. Methods: This study was performed on 27 cognitively normal young adults (ages 20‐35 years). Flow data was acquired on a 3T Siemens Prisma using a 2D cine‐PC pulse sequence. Three consecutive flow measurements were acquired at the CA and C2‐C3 area. Intraclass correlation coefficient (ICC) and coefficient of variance (CV) were used to evaluate intrarater, inter‐rater, and test–retest reliability. Results: Among the 26 flow parameters analyzed, 22 had excellent reliability (ICC  0.80), including measurements of CSF stroke volume, flush peak, and fill peak, and 4 parameters had good reliability (ICC 0.60‐0.79). 16 flow parameters had a mean CV ≤ 10%, 7 had a CV ≤ 15%, and 3 had a CV ≤ 30%. All CSF and CBF flow measurements had excellent inter‐rater and intrarater reliability (ICC  0.80). Conclusion: This study shows that CSF and CBF flow can be reliably measured at the CA and C2‐C3 area using PC‐MRI, making it a promising tool for studying flow dynamics in the central nervous system.","tags":[],"title":"Assessing test–retest reliability of phase contrast MRI for measuring cerebrospinal fluid and cerebral blood flow dynamics","type":"publication"},{"authors":[],"categories":["Virtual Reality"],"content":" Background Garbage Collection Polygon Count Draw Calls Camera Culling Static Batching References   Background The majority of VR headsets on the market use a 90 Hz refresh rate, such that the display on the headset is refreshed every 11 ms. Dropped frames will occur if the computer is unable to render an image within that time frame. API’s employ several techniques to account for dropped frames. These include timewarp, asynchronous timewarp, interleaved reprojection, motion smoothing, and positional timewarp.4 While these techniques account for dropped frames to a certain extent, a poorly optimized game will still result in jittery views which can be quite nauseogenic. Therefore, performance optimization is a key component of VR game development. In this article, I will provide a brief overview of the most common techniques used to optimize performance. I will also provide links that provide a more in-depth discussion of each technique. Please note that this is not an exhaustive list of performance tips, rather a list of low hanging fruit that can lead to substantial improvements in performance.  Garbage Collection Garbage collection (GC) is a form of automated memory management.1 There are two types of memory allocation: heap and stack. Furthermore, there are two data types: primitive and non-primitive.3 Primitive data types include the following: bool, bytes, short, int, long, float, double, decimal, and char. All primitive data type values are stored in stack memory. Non-primitive data types are objects and include the following: class, struct, enum, array, and string. Non-primitive data types are known as reference types, as the stack memory only contains a reference to the value. The reference in the stack points to an object located in heap memory that contains the value . GC only track objects (non-primitive data types) that occupy space in heap memory.2 The job of GC is to free memory when the object is no longer being referenced in the stack memory.\nUnity uses the Boehm–Demers–Weiser GC5, which is a type of stop-the-world GC. This means that when GC is required, code execution will stop until the GC process is complete. Depending on the frequency of GC, this can result in dropped frames and significantly affect the smoothness of gameplay. The figure below illustrates code that minimizes garbage collection (GoodExample) and unnecessarily increases garbage collection (BadExample).\nIn the bad example, we are instantiating a new WaitForSeconds routine every second. This results in a heap memory allocation every time an instance of WaitForSeconds is created. Each heap memory allocation is going to trigger a garbage collection. To minimize garbage collection, a single instance of WaitForSeconds can be used used if the wait period is the same each time.\nFurther Reading:\nhttps://jacksondunstan.com/articles/2981 http://blog.tochasstudios.com/2015/11/cache-coroutines.html https://forum.unity.com/threads/c-coroutine-waitforseconds-garbage-collection-tip.224878/\n Polygon Count The primary responsibility of the GPU is to render an image to the screen. The complexity of an image can significantly impact rendering performance. In VR, the images that are rendered are 3D meshes. Briefly, all meshes are composed of smaller units known as polygons, which can be further decomposed into triangles. Triangles consist of vertices whose positions can be stored as an array of values (x,y,z). During rendering, the GPU first uses a vertex shader to compute where the triangle should be placed on the screen and then uses a fragment shader to fill in the pixels (rasterize) within the vertices of the triangle.6 With modern GPU’s, polygon counts aren’t typically a bottleneck for performance. However, it’s still good practice for developers to simplify meshes in situations where detailed renderings aren’t needed. Blender is a free 3D modeling program that has the ability to simplify a mesh using the decimate function.\nFurther Reading:\nhttp://software.intel.com/en-us/articles/model-for-real-time-beyond-counting-polygons/\n Draw Calls A draw call is an instruction sent from the CPU to the GPU to render an image to the screen. An excessive number of draw calls can bottleneck the CPU if it is unable to push all draw call instructions to the GPU within that frame. In Unity, a draw call is required any time the GPU has to render a material. Multiple materials can be assigned to a single mesh, while a single diffuse texture is typically assigned to each material. A mesh consisting of 4 materials would require 4 separate draw calls from the CPU. The number of draw calls can be minimized by combining multiple meshes into a single mesh and applying a single material to that mesh. The use of a single material is possible through texture atlases, which map out how a texture is laid onto a material. MeshBaker on the Unity Asset Store is a popular asset that allows user’s to combine meshes and create texture atlases.7\nFurther Reading:\nhttps://medium.com/@toncijukic/draw-calls-in-a-nutshell-597330a85381\n Camera Culling By default, the camera in the game will render everything within its FOV. However, this is not always necessary as the user’s viewing depth is typically limited by vegetation, buildings, and other objects within the scene. Consider setting a culling distance such that any objects past that distance are not rendered. Game objects can even be assigned to different layers and a separate culling distance can be used for each layer. For example, flowers may require a shorter culling distance while larger landmarks may require a larger culling distance.\nFurther Reading:\nhttps://docs.unity3d.com/ScriptReference/Camera-layerCullDistances.html\n Static Batching For any object that isn’t moving in the environment, enable static batching. This combines all meshes that have the same material into 1 and renders it in 1 draw call. The negative is increased memory overhead. However, the advantage of this over consolidating into 1 mesh is that you can still cull each object individually.  References  “Garbage collection (computer science) – Wikipedia.” [Online]. Available: https://en.wikipedia.org/wiki/Garbage_collection_(computer_science). [Accessed: 19-Jun-2019]. “Feature Preview: Incremental Garbage Collection – Unity Blog.” [Online]. Available: https://blogs.unity3d.com/2018/11/26/feature-preview-incremental-garbage-collection/. [Accessed: 19-Jun-2019]. “C# Variables: Primitive and Non-primitive Types.” [Online]. Available: http://www.jeremyshanks.com/c-variables-primitive-nonprimitive-types/. [Accessed: 19-Jun-2019]. D. Heaney, D. Jagneaux, J. Feltham, and J. Feltham, “VR Timewarp, Spacewarp, Reprojection, And Motion Smoothing Explained,” UploadVR, 18-Jan-2019. [Online]. Available: https://uploadvr.com/reprojection-explained/. [Accessed: 15-Jul-2019] A garbage collector for C and C++. (2019). Retrieved from https://www.hboehm.info/gc/ Eskil_steenberg. “Model for Real Time-Beyond Counting Polygons.” Intel® Software, Intel, 15 Dec. 2018, software.intel.com/en-us/articles/model-for-real-time-beyond-counting-polygons. Digital Opus, digitalopus.ca/site/mesh-baker/.      ","date":1565329360,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565329360,"objectID":"67f8937f5fadc3f29daf4d29ad61434e","permalink":"https://arsakhar.github.io/blog/game-optimization/","publishdate":"2019-08-08T22:42:40-07:00","relpermalink":"/blog/game-optimization/","section":"blog","summary":"Tips for optimizing performance on virtual reality games built with Unity3D","tags":["Virtual Reality"],"title":"Unity3D - Performance Optimization","type":"blog"},{"authors":[],"categories":["Virtual Reality"],"content":" Background Treadmills Bikes References   Background Developing games that require locomotion is a significant challenge in virtual reality, as freedom of movement is restricted by cables on a tethered headset and transmitter signal strength on a wireless headset. Furthermore, movement is also constrained to the dimensions of the physical space in which movement is occurring.\nTo circumvent this problem, companies and research labs have developed solutions that allow user’s to move through a virtual environment while remaining stationary. In this post, i’ll highlight two of the most popular locomotion techniques in VR: treadmills and stationary exercise bikes.\n Treadmills Virtuix ( https://www.virtuix.com/ ) was one of the first companies to tread into the space of VR locomotion with a kickstarter campaign in June 2013.5 The Virtuix Omni is an omni-directional treadmill that allows users 360 degrees freedom of movement. A brief description of the system is below:\n“To use the Omni system, players wear special overshoes which stretch to fit over normal footwear. The player is held in place by a comfortable but firm harness. The HTC Vive VR headset is dropped down from above each player, so no wires get in the way to disrupt the VR illusion. The players’ feet slide along the plastic dish under their feet, while inside the simulation, they move forward, providing the unique full immersion of free roam VR in a much, much smaller space.”1\nhttps://www.virtuix.com/virtuix-omni-rides-vr-esports-explosion-to-one-million-plays/\rOther VR treadmills include:2,3,4\nKatVR (https://katvr.com/)\nCyberith Virtualizer (https://www.cyberith.com/)\nOmnideck (http://omnifinity.se/)\nInfinadeck (https://www.infinadeck.com/)\nThe Aperium Pod (http://aperiumreality.com/index.php/en/home/)\nSpacewalker VR (http://www.spacewalkervr.com/)\nThe KatVR, Cyberith Virtualizer, Aperium Pod, and Spacewalk VR are considered “slidemills”, as they require the user to slide their feet against a platform to engage in locomotion. The omnideck and infinideck are equipped with a variable-speed treadmill platform that utilizes positional feedback to ensure the user is always located near the center of the platform.\n Stationary Exercise Bikes In 2016, VirZoom (https://www.virzoom.com/) released the first stationary exercise bike designed to support locomotion in VR. The bike (pictured below) is equipped with a number of buttons on the handlebars, making it well-suited for gaming and exercise.\nhttps://www.roadtovr.com/virzoom-closes-5-5m-seed-funding-develop-second-generation-vr-bike-kit/\rOther VR bikes include:\rNordicTrack VR (https://www.cnet.com/news/nordictracks-vr-fitness-bike-wore-me-out-at-ces/)\n References  https://www.virtuix.com/virtuix-omni-rides-vr-esports-explosion-to-one-million-plays/ https://packet39.com/blog/2018/03/25/vr-treadmill-overview-march-2018/ https://www.vrfitnessinsider.com/vr-omnidirectional-treadmills-making-gains-towards-full-immersion-and-cardio/ https://www.aniwaa.com/blog/best-vr-treadmills-vr-slidemills/ https://en.wikipedia.org/wiki/Virtuix_Omni      ","date":1549233047,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549233047,"objectID":"3ebfa4512570c4896a0b34263a811e5b","permalink":"https://arsakhar.github.io/blog/commercial-locomotion/","publishdate":"2019-02-03T15:30:47-07:00","relpermalink":"/blog/commercial-locomotion/","section":"blog","summary":"An overview of commercially available devices for locomotion in virtual reality","tags":["Virtual Reality"],"title":"Locomotion in Virtual Reality","type":"blog"},{"authors":[],"categories":["Data Science"],"content":" Objective Data Acquisition Pre-Processing Training Results Discussion References Skills   Problem Statement Meningiomas are tumors that form on the meninges, a membrane that covers the brain and spinal cord. The current standard of treatment is a craniotomy where the skull is opened to provide access to the tumor. Recent technological advances have allowed meningioma’s to be resected using minimally invasive endoscopic or key-hole surgical approaches.1 The selection of patients for these minimally invasive surgeries are based on several tumor characteristics such as pathology, vascularity, and invasiveness.1\nOne key characteristic that dictates ease of operation is tumor consistency, defined as texture or firmness.1 Tumor consistency, which can only be measured after surgical resection, is graded on a 5-point hardness scale (1-softest, 5-hardest).1,2 Training a machine learning model to classify a tumor according to its hardness using neuroimaging data could help physicians determine if a patient is a candidate for minimally invasive surgery.\nObjective To train a convolutional neural network to classify meningioma tumors based on hardness ratings.\nCode can be downloaded at: https://github.com/arsakhar/ML-Meningioma-Classification\n Data Acquisition MRI scans were acquired on 85 patients across several hospitals. For each patient, an ADC, T2 flair, T1, T1 with contrast (T1c), and T2 scan were acquired. A lesion mask was manually created by the physician after image acquisition. Resected meningioma’s were manually labeled using a 0-3 hardness scale by expert raters.\n\n Pre-Processing A supervised learning task for multi-class classification was considered based on the provided labels and discrete grading scale. A convolutional neural network classifier was chosen as the inputs were images.\nThe bar chart below shows the distribution of meningioma classes for the acquired data. Class 0 and 1 were the lowest and highest frequency, respectively. Overall, the dataset was highly imbalanced between classes 1, 3 and 1,2. Moreover, only a limited sample of 425 scans (85 patients and 5 scans per patient) were available for training the model.\n\nOne issue with the acquired data was that the dimensions of the scans were consistent within a subject but differed between subjects. Briefly, an MRI scan is a 3D volume of height, width, and depth where depth represents the number of slices.\nTo ensure a consistent input shape into the CNN, each scan was resampled to a size of 256x256xZ. Z was set to 256 if the image had less than 256 slices. Otherwise, the original number of slices was retained.\n\nTo increase the number of available training samples, each scan was decomposed into its individual slices.\n\nThe figure below illustrates multiple slices across a single scan.\n\nEach individual slice was then re-assigned the original class label only if it contained the lesion based on the lesion mask. Slices that did not contain a lesion were not included in training the model. Decomposing and re-assigning class labels increased the accuracy of the label assignments as a single label was no longer applied to an entire 3D volume.\n\n Training Residual Neural Network 152 (ResNet 152) was selected as the CNN model for training. The following hyperparameters were randomly selected and evaluated using Optuna:\nOptimizer – Adam, RMSprop, SGD\rLearning Rate – log uniform distribution, [1e-6, 1e-1]\rDropout – uniform distribution, [0.1, 0.7]\rBatch Size – categorical, [16, 32, 64, 128]\rL2 Regularization – log uniform distribution, [1e-10, 1e-3]\r\rThe remaining training parameters were set as follows:\nInput Channels – 5 [t1, t1c, t2 flair, t2, adc]\r# Classes – 4\r# Epochs – 45\rLoss function – cross-entropy\r\rThe cross-entropy loss function was weighted according to the distribution of classes in the dataset.\n\nTwo modifications were made to the original ResNet152 model. The first convolutional layer was modified to accept 5 input channels instead of 3 and the fully connected layer was modified to output probabilities for 4 classes instead of 1000.\n\nThe ResNet 152 model was trained using 5-fold cross validation. The folds were stratified by subject to ensure all slices associated with a single subject were constrained to a single fold. Briefly, neighboring slices within a scan are structurally similar as they are anatomically acquired a few mm apart. This problem is exacerbated in subjects where the scan is up sampled to 256 slices during preprocessing. The similarity of slices results in data leakage if the slices are spread across the training and test fold. The folds were also stratified by class label to ensure the distribution of classes in the training and test fold approximated the actual distribution of classes for the acquired data.\nA custom dataset class was used to load, augment, and transform the slices to tensors for input into the CNN. TorchIO, a python package for medical image preprocessing, was used for data augmentation. Briefly, both training and validation slices were normalized to a mean of zero and standard deviation of one. Training slices were also augmented with a random blur, noise, bias field, motion, spike, ghosting, affine transformations, and elastic deformations at specified probabilities. This was done to provide additional unique images for the CNN to train on in the absence of a large training dataset.\n\nEach epoch consisted of a training and validation iteration. Both iterations consisted of a forward pass. Loss was calculated using the SoftMax output and target labels. The weights and bias in each layer were updated via back propagation for the training iterations. The argmax of the SoftMax output probabilities was used to calculate accuracy, defined by the proportion of correct predictions to total predictions.\n Results Overall, the trained CNN model performed poorly on the validation dataset across multiple sets of hyperparameters selected by Optuna. The figure below shows the training and validation loss accuracy for a single fold and set of hyperparameters. As expected for training, the loss decreased (solid black line) and accuracy (dashed black line) increased, with accuracy approaching 95% after 45 epochs. However, validation loss (solid red line) and validation accuracy (dashed red line) did not improve during training. Validation loss decreased for the first 10 epochs before increasing. The validation accuracy increased to approximately 35% after 10 epochs before decreasing to 20%. Therefore, overfitting likely occurred after the 10th epoch.\n\nThe confusion matrix, calculated as a normalized sum of the confusion matrices for each k-fold, can be seen below. Of the meningiomas with an actual label of zero, the model correctly labeled 17%, while incorrectly labeling 34% and 47% as one and two, respectively. Of the meningiomas with an actual label of three, the model correctly labeled 12%, while incorrectly labeling 18% and 65% as one and two, respectively.\n\n Discussion Overall, the CNN was unable to classify Meningioma’s with high accuracy and generalized very poorly to unseen validation data. The highest validation accuracy across the training folds was only 35% which is marginally better than 25% due to random guessing. The poor validation accuracy was seen for multiple combinations of hyperparameters decreasing the likelihood that the results were due to a poorly optimized model.\nPoor model performance may be due a lack of discernible patterns between classes of meningioma observed on an MRI. Indeed, it is possible that the biological properties underlying the tactile hardness, texture, and consistency differences observed by the expert rater during grading are not detectable on an MRI. It is also possible that inter-rater and intra-rater variability resulted in misclassification of some meningioma’s during labeling. This variability could affect model training as the labels are not representative of the actual ground truth.\nDespite the poor overall accuracy, the model was able to discriminate between the extreme classes, zero and three, relatively well. As seen in the confusion matrix, the model rarely assigned class three to class zero and vice versa. Taken together, this suggests that there may be a detectable pattern between classes.\nFuture Directions Due to computational requirements, the grid search for the optimal hyperparameters was only run for 3 iterations. Furthermore, only the ResNet 152 CNN was trained. Training additional CNN’s and continuing the grid search over 10-15 iterations may yield a trained model better suited for the provided dataset. Different data augmentation techniques may also improve model training as well. However, these changes will likely only result in a marginal improvement in classification accuracy. To evaluate whether Meningioma’s acquired by MRI can be classified with high accuracy, additional training data is needed.\nIn the absence of additional training data, one possibility is to run an unsupervised machine learning technique such as k-means clustering over a range of clusters. A scree plot or silhouette analysis can then be used to identify the optimal number of clusters. The labels of the images in each cluster can then be compared to identify the purity of the cluster. If the optimal number of clusters is 4, it would suggest there is a detectable pattern aligned with the expected number of classes. Moreover, if the incorrectly labeled images in each cluster are better suited for the nearest neighboring cluster. it may suggest that inter-rater and intra-rater variability are contributing to problems with model training.\n References  Shiroishi, Mark S., et al. \u0026ldquo;Predicting meningioma consistency on preoperative neuroimaging studies.\u0026rdquo; Neurosurgery Clinics 27.2 (2016): 145-154. Zada, Gabriel, et al. \u0026ldquo;A proposed grading system for standardizing tumor consistency of intracranial meningiomas.\u0026rdquo; Neurosurgical focus 35.6 (2013): E1.   Technical Skills \rPre-processing MRI data\rManipulating and training a convolutional neural network for image classification\rCross-validation for small datasets\rGenerating classification reports and confusion matrices\r\rPackages \rOptuna\rNiBabel\rPandas\rNumPy\rTorch\rTorchvision\rScikit-learn\rTorchIO\r\r    ","date":1549233047,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549233047,"objectID":"adf3d0e1b7da63c95318dd76c4394c87","permalink":"https://arsakhar.github.io/project/meningioma/","publishdate":"2019-02-03T15:30:47-07:00","relpermalink":"/project/meningioma/","section":"project","summary":"Using machine learning to predict Meningioma consistency","tags":["Data Science"],"title":"Meningioma Classification using Machine Learning","type":"project"},{"authors":["Vihar C Surti","Ashwin Rajan Sakhare"],"categories":[],"content":"","date":1329287619,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1329287619,"objectID":"e508e60e89c06f98e0bfb9580f462f59","permalink":"https://arsakhar.github.io/publication/us-patent/","publishdate":"2020-05-23T23:33:39-07:00","relpermalink":"/publication/us-patent/","section":"publication","summary":"A stylet locking mechanism for preventing axial movement of a stylet relative to a needle of a medical delivery device is disclosed. The locking mechanism comprises first and second ends that may be removably attached to the device, and a hinge for allowing the locking mechanism to be disengaged from a locking position without being completely disconnected from the delivery device.","tags":[],"title":"Stylet locking mechanism for medical delivery devices","type":"publication"},{"authors":null,"categories":null,"content":" Software Pipelines   NeuroFlow\nA brain imaging tool for analyzing cerebral flow dynamics. (Read)\r  The following are brain imaging pipelines I have used extensively as part of my research on aging and AD dementia. As a result, I have a strong background in visualizing, processing, and analyzing a number of different MRI modalities. This includes assessing brain morphometry on T1 and T2 images, as well as flow on PC-MRI images.\r\nHippocampal Subfields\nASHS (external) is a tool for segmenting and labeling the hippocampal subfields and medial temporal lobe (MTL). The software uses T1 and T2 weighted MRI’s to segment the MTL and hippocampal subfields.\nPurpose:  The entorhinal cortex, CA1, and CA4/dentate gyrus subfields of the hippocampus have been linked to aging and AD pathology and have also been shown to be important for spatial memory (Yushkevich PA., et al., 2014).\n\nGeneral Brain Morphometry\nFreesurfer (external) is an open source software suite for processing and analyzing human brain MRI images. The software uses T1 MPRAGE images to segment the brain.\nPurpose:  Studies have shown that whole brain volumes decrease approximately .45% per year in older adults (Fotenos Anthony F., et al., 2005).\n\nCerebral Flow Dynamics\nNeuroFlow (written by me) is a brain imaging tool for analyzing cerebral flow dynamics. Another, older option, is BioFlow (Balédent O, et al., 2001).\nPurpose:  The cerebral aqueduct (CA) and C2-C3 region have been shown to be sensitive to the pathological changes that occur in aging and Alzheimer’s disease (El Sankari S., et al., 2011).\n\nPerivascular Spaces\nThe PVS Pipeline is an in-house pipeline tool written by Dr. Farshid Sepehrband.\rPurpose:  Perivascular space size is associated with Alzheimer\u0026rsquo;s disease (Banerjee G., et al., 2017)\n\n    ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"eee24ad29bc58dbaa59968453b323abc","permalink":"https://arsakhar.github.io/brain-imaging/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/brain-imaging/","section":"","summary":"Software Pipelines   NeuroFlow\nA brain imaging tool for analyzing cerebral flow dynamics. (Read)\r  The following are brain imaging pipelines I have used extensively as part of my research on aging and AD dementia.","tags":null,"title":"Brain Imaging","type":"brain-imaging"},{"authors":null,"categories":null,"content":" Software   FitViz\nANT+ Health and Fitness Monitoring Client. (Read)\r     ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"158297db075994183d3d0353053415d8","permalink":"https://arsakhar.github.io/clinical-research/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/clinical-research/","section":"","summary":" Software   FitViz\nANT+ Health and Fitness Monitoring Client. (Read)\r     ","tags":null,"title":"Clinical Research","type":"clinical-research"},{"authors":null,"categories":null,"content":" Machine Learning Data Science   Meningioma Classification using Machine Learning\nUsing machine learning to predict Meningioma consistency. (Read)\r\nPhoto Credit: Basaia, Silvia, et al. NeuroImage: Clinical 21 (2019)\r Ranking College Football Coaches\nUsing data science to evaluate recruiting and player development in college football. (Read)\r     ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"50e35ac143cf0d837a0f8f82dd935fd2","permalink":"https://arsakhar.github.io/data-science/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/data-science/","section":"","summary":"Machine Learning Data Science   Meningioma Classification using Machine Learning\nUsing machine learning to predict Meningioma consistency. (Read)\r\nPhoto Credit: Basaia, Silvia, et al. NeuroImage: Clinical 21 (2019)\r Ranking College Football Coaches","tags":null,"title":"Data Science","type":"data-science"},{"authors":null,"categories":null,"content":" Inspiration Games Bike Responsibilities Skills News Coverage   Inspiration Alzheimer disease is the leading cause of dementia in older adults. To date, there are no effective disease-modifying treatments, but recent studies have shown exercise and cognitive stimulation to be associated with a reduced risk of dementia. Virtual reality is a promising technology for combining exercise and cognitive stimulation and may enhance brain health in older adults at risk for Alzheimer\u0026rsquo;s disease.  Games Sal\u0026rsquo;s Sanctuary and Wildlife Enclosure are two fun, engaging, and cognitively challenging virtual reality exergames designed specifically for older adults. A third game, Underwater Adventures is currently in development.\nSal\u0026rsquo;s Sanctuary - Rescue animals that have escaped the sanctuary while navigating an urban environment\nWildlife Enclosure - Look after and take care of rescued animals located in exotic environments\nUnderwater Adventures (In Development) - Explore and photograph aquatic life in this underwater world\n Bike NeuroRiderVR - A novel, custom-built exercise bike designed specifically for older adults and locomotion in VR.  Responsibilities \rDeveloped a cognitively challenging exergame in virtual reality for older adults (Lead Engineer)\rDeveloped a custom-built exercise bike (Lead Engineer)\rDeveloped the environments, physics, and interaction system for the game\rCollaborated with a small, high-energy team of undergraduate students, master students, and professors\rOptimized performance by utilizing assets and other techniques to reduce rendering overhead in virtual reality\rIntegrated a heart rate monitor into to the game for monitoring a users heart rate and heart rate variability\rIntegrated a custom-built exercise bike as an input controller for biking in the game\rDesigned and developed a SQL database to store game data\rDesigned and developed a login and registration system to manage a user’s session\rInstalled and maintained a version control server\r\r Soft Skills \rLeading small teams on large-scale, long-term projects\rCollaborating and communicating effectively on cross-functional, multi-disciplinary teams\rAdapting to a rapidly changing work environment\rDeveloping creative solutions to challenging problems\r\rTechnical Skills \rDeveloping serious games for virtual reality\rCreating 3D CAD parts and assemblies In SolidWorks\rDesigning for manufacturing and working with the machine shop\rDesigning and soldering circuits\rDesigning levels, game physics and interaction systems in Unity 3D\rWorking with assets, scripts, prefabs, textures, animation, GUI, events, and scriptable objects in Unity3D\rFamiliarity with design patterns and interfaces\rWriting clean, readable, and easily maintainable code\rCreating and maintaining a version control server\r\rSoftware \rPerforce\rSolidWorks\rUnity3D\rVisual Studio\rXAMPP\r\rProgramming Languages \rC#\rPHP\rSQL\rC/C++ (Arduino)\r\rPackages \rUnityEngine.Networking – HTTP communication with web server\rUnityEngine.UI\rSystem.Linq\rSystem.Net.Sockets – Udp communication\rSystem.Threading\rSystem.IO.Ports – serial port communication\rUnityEngine\rUnityEngine.AI - pathfinding\rstdlib.h - standard Arduino library\rResponsiveAnalogRead.h - analog input noise reduction\r\r News Coverage Morning Joe\n\r\r\nVoice of America\n\r\r\nhttps://www.voanews.com/science-health/scientists-study-whether-virtual-reality-can-prevent-cognitive-decline-dementia\n    ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"4435cfd945dd8998a0fc968a7635e8ff","permalink":"https://arsakhar.github.io/virtual-reality/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/virtual-reality/","section":"","summary":"Inspiration Games Bike Responsibilities Skills News Coverage   Inspiration Alzheimer disease is the leading cause of dementia in older adults. To date, there are no effective disease-modifying treatments, but recent studies have shown exercise and cognitive stimulation to be associated with a reduced risk of dementia.","tags":null,"title":"Virtual Reality","type":"virtual-reality"}]