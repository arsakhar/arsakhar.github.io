<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title></title>
    <link>https://arsakhar.github.io/</link>
      <atom:link href="https://arsakhar.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description></description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Sun, 28 Jun 2020 22:19:19 -0700</lastBuildDate>
    <image>
      <url>https://arsakhar.github.io/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title></title>
      <link>https://arsakhar.github.io/</link>
    </image>
    
    <item>
      <title>NeuroRiderVR</title>
      <link>https://arsakhar.github.io/project/vr-bike/</link>
      <pubDate>Sun, 28 Jun 2020 22:19:19 -0700</pubDate>
      <guid>https://arsakhar.github.io/project/vr-bike/</guid>
      <description>&lt;h3 id=&#34;background&#34;&gt;Background&lt;/h3&gt;
&lt;p&gt;In a recent blog post (&lt;a href=&#34;https://arsakhar.github.io/blog/commercial-locomotion/&#34;&gt;Locomotion in VR&lt;/a&gt;), I detailed some of the current technology that exists for locomotion in VR. Until recently, VirZoom was the only virtual reality bike on the market. However, at CES 2019, Nordic Track announced the release of their VR bike. This is great news for VR as many of the bigger companies are starting to see the value of VR in exercise and entertainment. The target audience for both VR bikes are generally younger to middle aged adults with a focus on entertainment, exercise, and gaming.&lt;/p&gt;
&lt;p&gt;In our academic research lab, we focus on the applications of VR to rehabilitation in an older adult population. At the time of our VR biking study in older adults, the Nordic Track VR bike did not exist. While the VirZoom bike was a possibility, we did have several concerns. Turning in VR with the VirZoom bike is achieved by leaning one&amp;rsquo;s body in the intended direction of movement. VirZoom claims that this is a more natural method of turning that minimizes motion sickness and improves user safety while riding the VR bike.&lt;/p&gt;
&lt;p&gt;When we tried the VirZoom bike in our lab, our initial impressions were that it was a bit unnatural. While it&amp;rsquo;s possible that users would adjust to this over time, we thought the older adult population might do better on a bike with a turning mechanism that more closely resembled that of an actual bike. Furthermore, we hypothesized that requiring older adults to lean might introduce an additional safety risk, particularly in those with poor postural stability.&lt;/p&gt;
&lt;h3 id=&#34;objective&#34;&gt;Objective&lt;/h3&gt;
&lt;p&gt;Our objective was to develop a custom bike that would allow for turning in VR by the same mechanism of a regular bike, rotating the handlebar clockwise or counter-clockwise. Moreover, we wanted our design to include digital control of the pedal resistance. This would allow for real-time manipulation of pedal resistance when participants were going up or down hills in a VR environment or as a means to increase a participants exertion during exercise.&lt;/p&gt;
&lt;h3 id=&#34;design-requirements&#34;&gt;Design Requirements&lt;/h3&gt;
&lt;p&gt;The primary design requirements for our custom bike were stability, comfort, and ease of access for older adults. The bike was required to accommodate adults of different heights, trunk, leg, and arm lengths, and the turning and braking mechanisms for our bike were to be similar to that of a road bike. Furthermore, the bike was to be designed such that the pedal resistance could be manipulated from the computer in real-time. Finally, the bike should be able to interface with a computer and provide speed, turning, temperature, and braking feedback.&lt;/p&gt;
&lt;h3 id=&#34;mechanical-design&#34;&gt;Mechanical Design&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://arsakhar.github.io/img/vr-bike/cad-model.png&#34; alt=&#34;Example image&#34;&gt;&lt;/p&gt;
&lt;p&gt;The first step in the design process was to create a model of the bike using SolidWorks, a 3D CAD software. We then had the bike fabricated at our University&#39;s (USC) machine shop. The drivetrain, handlebar, and seat post frames were welded and constructed out of aluminum to reduce weight and cost. All other components, including the leg stabilizers and gearing mechanism within the drive train were bolt-mounted for ease of assembly/disassembly. The bike was comprised of adjustable angled telescopic seat and handlebar posts. The handlebar was mounted to a ball-bearing to allow approximately 150 degrees rotation. A brass set screw was used to manually adjust the resistance to turning. The bike consisted of a double gear reduction such that the output torque was approximately 11.5% of the input torque. A freewheel sprocket was used to allow for coasting. Radially oriented electromagnets were mounted concentrically inside a flywheel to allow for varying of pedal resistance using the principles of eddy current braking.&lt;/p&gt;
&lt;h3 id=&#34;electrical-design&#34;&gt;Electrical Design&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://arsakhar.github.io/img/vr-bike/circuit.png&#34; alt=&#34;Example image&#34;&gt;
&lt;img src=&#34;https://arsakhar.github.io/img/vr-bike/schematic.png&#34; alt=&#34;Example image&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Speed Detection&lt;/b&gt;&lt;br&gt;
Speed detection was achieved using a custom laser-cut acrylic encoder wheel and Omron EE-SV3-D transmissive optical sensor. The optical sensor consisted of a photodiode (light emitter) and phototransistor (light detector). A standard 220 Ω resistor was connected in series between the 5V supply voltage and anode to keep the forward current within its specified current rating. The phototransistor was configured as a common collector (CC) phototransistor circuit. A 10 kΩ load resistor was added between ground and the emitter to configure the phototransistor for switch mode (), where the output was either OFF or ON based on the absence or presence of light, respectively. It should be noted that a 5 kΩ load resistor is typically adequate for switch mode and will have a faster response time to changes in light intensity compared to a 10 kΩ load resistor. The output signal from the collector was connected to a digital pin on the Arduino.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Turning and Brake Sensing&lt;/b&gt;&lt;br&gt;
A linear, rotatory 10 kΩ potentiometer and dual-axis XY joystick module were used for turning and brake sensing, respectively. Both sensors were configured as voltage dividers, outputting a voltage between 0V and the 5V supply voltage based on the rotation of the knob or the deflection of the joystick.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Temperature Sensor&lt;/b&gt;&lt;br&gt;
A TMP36 semi-conductor temperature sensor was used to monitor heat dissipation at the electromagnet coils. A 100 nF capacitor was added between the output pin and ground for each sensor to dampen signal fluctuations due to mechanical bounce, electrical noise, and electromagnetic interference. The output pin on each sensor was connected to a unique analog pin on the Arduino.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Pedal Resistance&lt;/b&gt;&lt;br&gt;
Pulse width modulation (PWM) and a RFP30N06LE MOSFET transistor were used to manipulate pedal resistance. An HCPL-7710 opto-isolator was placed between the Arduino’s digital PWM signal and the MOSFET to electrically isolate the MOSFET from the Arduino. Indeed, the high PWM signal frequency (490 Hz) resulted in frequent switching of the MOSFET which caused undesirable noise during signal sampling. The PWM signal was connected to pin 2 of the opto-isolator. Arduino’s 5V power supply and ground were connected to pins 1 and 4 of the opto-isolator. 12V from an external variable power supply was regulated down to 5V via a L7805ABV linear voltage regulator and connected to pin 5 of the opto-isolator. Pin 8 of the opto-isolator was connected to ground of the external power supply. A 100 nF capacitor was connected between pins 1 and 4 and 5 and 8 of the opto-isolator in accordance with datasheet recommendations. Similarly, a 330 nF and 100 nF capacitor were connected between ground and the voltage regulator input and output pins, respectively.&lt;/p&gt;
&lt;p&gt;The opto-isolated PWM signal at pin 6 of the opto-isolator was connected to the gate pin on the MOSFET. A 47 Ω gate resistor was placed in series with pin 6 of the opto-isolator and the MOSFET gate to limited ringing and electrical noise due to parasitic inductance. A 10 kΩ pull-down resistor was connected in series between ground and the MOSFET gate to pull the voltage down and turn the MOSFET off in the absence of a PWM input signal. The MOSFET source was connected to the source of the MOSFET. One electromagnet lead was connected to the source of the MOSFET, while the other was connected to 12V power from the external power supply. An 1N5817 Schottky diode was connected in parallel with the leads of the electromagnet to prevent flyback when current to the electromagnet is interrupted. A 2000 µF electrolytic capacitor and 100 nF capacitor were connected in parallel across 12V power and ground from the external power supply to smooth out the input voltage to the electromagnet.&lt;/p&gt;
&lt;h3 id=&#34;arduino-programming&#34;&gt;Arduino Programming&lt;/h3&gt;
&lt;p&gt;The temperature, turning, and braking sensors were connected to analog input pins, the speed sensor was connected to a digital input pin, and pedal resistance was provided by a PWM output pin on the Arduino Uno. The Arduino Uno connected to the PC via a USB A-Male to B-Male cable. A standard Arduino Uno driver was used to establish the connection as a COM port on the PC. The baud rate was set to 1,000,000 for serial port communication.&lt;/p&gt;
&lt;p&gt;The ResponsiveAnalogRead library was used to reduce noise associated with the analog input signals for the brake, turning, and temperature sensors. All analog sensor values were updated within the main loop. For the speed sensor, an interrupt trigger was used to track when the state of the optical sensor changed. A digital pin reads HIGH(1) when the voltage signal is &amp;gt; 3.0V and LOW(0) when the voltage is &amp;lt; 3.0V on a 5V Arduino board.&lt;/p&gt;
&lt;p&gt;When determining speed, the Arduino code is structured to count the number of times the digital interrupt is triggered over a specified sampling period of 50ms. A digital interrupt is triggered when the encoder wheel spoke enters and leaves the light path. The number of interrupts over this 50 ms period is then converted to a speed using the following formula:&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Interrupt Count&lt;/b&gt; (counts/s) = Interrupt Count * (1 / 50 ms) * (1 / 1000s)
&lt;br&gt;&lt;b&gt;Speed (m/s)&lt;/b&gt; = (2 * pi * Flywheel Radius (m)) / (Spokes per Revolution) * (Interrupt Count)&lt;/p&gt;
&lt;p&gt;Note: In practice, an additional fudge factor may be necessary to get the perceived pedal speed to correctly match the speed at which the user moves through the virtual environment&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Encoder Wheel&lt;/b&gt;&lt;br&gt;
The encoder wheel was mounted to the output shaft of the flywheel and centered within the gap of the optical sensor. For the encoder wheels, we laser cut 6 different variations out of acrylic. These variations included 2, 4, 8, 16, 32, 64, and 128 spokes. For each wheel, we evaluated 2 conditions: aliasing and a ceiling effect. Aliasing occurs when the encoder wheel rotates faster than the optical sensor can react to the light change or the Arduino can trigger the digital interrupt pin. With a 10K load resistor, the response time of the phototransistor is approximately 100 µs. With the Arduino, the interrupt service routine theoretically executes every .625 µS based on a clock speed of 16 MHz.&lt;/p&gt;
&lt;p&gt;However, in practice, this is often much slower due to factors such as code overhead and often results in an interrupt frequency on the scale of milliseconds, which likely makes it the rate limiting step. The ceiling effect occurs when the resolution of the encoder wheel is too small to capture the actual pedal speed. In other words, after a certain pedal speed, the number of spokes that pass through the optical sensor gets capped over a 50 ms period. During testing, we found that the 2,4,8, and 16 spoke encoder wheels experienced the ceiling effect while the 128 spoke encoder wheel had significant aliasing at normal pedal speeds. We found the 64 spoke encoder wheel to be the best option as we found no aliasing and no ceiling effect, even at very high pedal speeds.&lt;/p&gt;
&lt;h3 id=&#34;acknowledgements&#34;&gt;Acknowledgements&lt;/h3&gt;
&lt;p&gt;The bike design was a team effort with significant contributions from Roshan Ravichandran (lead mechanical design) and Delian Delev (lead electrical design). Additional design support was provided by Chintan Raja and Vincent Yang. Electromagnet guidance was provided by Andrew Bushnell. Special thanks to Don Wiggins and the USC machine shop for manufacturing the bike.&lt;/p&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>FitViz</title>
      <link>https://arsakhar.github.io/project/fitviz/</link>
      <pubDate>Fri, 05 Jun 2020 23:32:49 -0700</pubDate>
      <guid>https://arsakhar.github.io/project/fitviz/</guid>
      <description>&lt;div class=&#34;article-container-nav&#34;&gt;

	&lt;nav&gt;
	
		&lt;div class=&#34;sticky-scroll navtab-position nav flex-row nav-pills&#34; id=&#34;nav-tab&#34; role=&#34;tablist&#34;&gt;
			&lt;br&gt;
			
			

			
			
			

			

			&lt;a class=&#34;nav-item nav-link active&#34; id=&#34;nav-1&#34; data-toggle=&#34;tab&#34; href=&#34;#tab11&#34; role=&#34;tab&#34;
				 aria-controls=&#34;nav-home&#34; aria-selected=&#34;true&#34;&gt;Overview&lt;/a&gt;

			
			

			
			
			

			

			&lt;a class=&#34;nav-item nav-link&#34; id=&#34;nav-1&#34; data-toggle=&#34;tab&#34; href=&#34;#tab12&#34; role=&#34;tab&#34;
				 aria-controls=&#34;nav-home&#34; aria-selected=&#34;false&#34;&gt;Skills&lt;/a&gt;

			
			
		&lt;/div&gt;
	&lt;/nav&gt;

	&lt;div class=&#34;article-style &#34;&gt;
		&lt;div class=&#34;tab-content&#34; id=&#34;1&#34;&gt;
			






&lt;div class=&#34;tab-pane fade show active&#34; id=&#34;tab11&#34; role=&#34;tabpanel&#34; aria-labelledby=&#34;nav-tabName1&#34;&gt;

	&lt;h4 id=&#34;overview&#34;&gt;Overview&lt;/h4&gt;
&lt;p&gt;FitViz is a monitoring client designed for fitness enthusiasts and gamers. It supports real-time visualization and tracking of health and fitness data sent from ANT+ devices. FitViz also provides networking capabilities allowing game developers to easily integrate ANT+ devices, such as bike trainers and heart rate monitors, into their own game.&lt;/p&gt;
&lt;p&gt;The idea behind this project was to provide a standalone PC application that allowed me to interface with a Wahoo Kickr Snap bike trainer. In particular, I was interested in obtaining real-time measurements of speed and power from the Wahoo Kickr to be used as an input controller for a VR game.&lt;/p&gt;
&lt;h4 id=&#34;about-ant&#34;&gt;About ANT+&lt;/h4&gt;
&lt;p&gt;ANT+ is a wireless sensor network technology that allows you to moniter data broadcast from ANT+ capable devices. Fitness equipment, bike trainers, heart rate monitors, and blood pressure monitors are just a few of the many devices supported within the ANT+ ecosystem. Data broadcast from ANT+ devices is standardized based on the type of data being sent. ANT+ refers to a data type as a device profile. An ANT+ device can broadcast data associated with multiple device profiles. For example, the Wahoo Kickr Snap broadcasts bicycle power and fitness equipment data.&lt;/p&gt;
&lt;h3 id=&#34;video&#34;&gt;Video&lt;/h3&gt;
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe width=&#34;560&#34; height=&#34;315&#34; src=&#34;https://www.youtube.com/embed/Eyo31jKeFIw&#34; title=&#34;YouTube video player&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;p&gt;FitViz can be downloaded at: &lt;a href=&#34;https://github.com/arsakhar/FitViz&#34;&gt;https://github.com/arsakhar/FitViz&lt;/a&gt;&lt;/p&gt;


&lt;/div&gt;











&lt;div class=&#34;tab-pane fade&#34; id=&#34;tab12&#34; role=&#34;tabpanel&#34; aria-labelledby=&#34;nav-tabName2&#34;&gt;

	&lt;h4 id=&#34;technical-skills&#34;&gt;Technical Skills&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;ANT+ Communication&lt;/li&gt;
    &lt;ul style=&#34;list-style-type:square;&#34;&gt;
      &lt;li&gt;Communicating with and reading sensor information from ANT+ devices&lt;/li&gt;
    &lt;/ul&gt;
  &lt;li&gt;Exporting Data&lt;/li&gt;
    &lt;ul style=&#34;list-style-type:square;&#34;&gt;
      &lt;li&gt;Writing data to UDP port&lt;/li&gt;
      &lt;li&gt;Saving data to CSV&lt;/li&gt;
    &lt;/ul&gt;
  &lt;li&gt;Visualization&lt;/li&gt;
    &lt;ul style=&#34;list-style-type:square;&#34;&gt;
      &lt;li&gt;Developing GUI&lt;/li&gt;
      &lt;li&gt;Displaying sensor values in real-time&lt;/li&gt;
    &lt;/ul&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;packages&#34;&gt;Packages&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;PyQt5&lt;/li&gt;
  &lt;li&gt;LibAnt&lt;/li&gt;
&lt;/ol&gt;


&lt;/div&gt;




		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

</description>
    </item>
    
    <item>
      <title>NeuroFlow</title>
      <link>https://arsakhar.github.io/project/neuroflow/</link>
      <pubDate>Fri, 05 Jun 2020 23:32:49 -0700</pubDate>
      <guid>https://arsakhar.github.io/project/neuroflow/</guid>
      <description>&lt;div class=&#34;article-container-nav&#34;&gt;

	&lt;nav&gt;
	
		&lt;div class=&#34;sticky-scroll navtab-position nav flex-row nav-pills&#34; id=&#34;nav-tab&#34; role=&#34;tablist&#34;&gt;
			&lt;br&gt;
			
			

			
			
			

			

			&lt;a class=&#34;nav-item nav-link active&#34; id=&#34;nav-1&#34; data-toggle=&#34;tab&#34; href=&#34;#tab11&#34; role=&#34;tab&#34;
				 aria-controls=&#34;nav-home&#34; aria-selected=&#34;true&#34;&gt;Overview&lt;/a&gt;

			
			

			
			
			

			

			&lt;a class=&#34;nav-item nav-link&#34; id=&#34;nav-1&#34; data-toggle=&#34;tab&#34; href=&#34;#tab12&#34; role=&#34;tab&#34;
				 aria-controls=&#34;nav-home&#34; aria-selected=&#34;false&#34;&gt;Skills&lt;/a&gt;

			
			
		&lt;/div&gt;
	&lt;/nav&gt;

	&lt;div class=&#34;article-style &#34;&gt;
		&lt;div class=&#34;tab-content&#34; id=&#34;1&#34;&gt;
			






&lt;div class=&#34;tab-pane fade show active&#34; id=&#34;tab11&#34; role=&#34;tabpanel&#34; aria-labelledby=&#34;nav-tabName1&#34;&gt;

	&lt;h4 id=&#34;overview&#34;&gt;Overview&lt;/h4&gt;
&lt;p&gt;NeuroFlow is an imaging tool that allows neuroscientists and clinicians to analyze cerebral flow dynamics in the brain. The continuous circulation of cerebrospinal fluid (CSF) and cerebral blood flow (CBF) is key to the health of our central nervous system. When CSF and CBF dynamics in the brain become dysregulated, pathophysiological states can occur. As such, cerebral flow dynamics may be an important biomarker for identifying meaningful alterations in neurological diseases.&lt;/p&gt;
&lt;p&gt;Phase-contrast MRI (PC-MRI) is a validated, non-invasive MRI imaging technique, allowing rapid measurements of CSF and CBF flow in the brain. NeuroFlow provides a user-friendly interface for neuroscientists and clinicians to analyze PC-MRI images and extract measurements associated with cerebral flow dynamics. Moreover, NeuroFlow provides numerous tools to help user&amp;rsquo;s quickly, accurately, and painlessly analyze flow data.&lt;/p&gt;
&lt;h3 id=&#34;video&#34;&gt;Video&lt;/h3&gt;
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe width=&#34;560&#34; height=&#34;315&#34; src=&#34;https://www.youtube.com/embed/VVsJvCKQgo0&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;p&gt;NeuroFlow can be downloaded at: &lt;a href=&#34;https://github.com/arsakhar/NeuroFlow&#34;&gt;https://github.com/arsakhar/NeuroFlow&lt;/a&gt;&lt;/p&gt;


&lt;/div&gt;











&lt;div class=&#34;tab-pane fade&#34; id=&#34;tab12&#34; role=&#34;tabpanel&#34; aria-labelledby=&#34;nav-tabName2&#34;&gt;

	&lt;h4 id=&#34;technical-skills&#34;&gt;Technical Skills&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;Reading and Loading DICOMDIR&lt;/li&gt;
    &lt;ul style=&#34;list-style-type:square;&#34;&gt;
      &lt;li&gt;Storing Patient, Study, Series, Sequence, and Image information entities of the DICOM data model in accordance with the NEMA DICOM standard.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;li&gt;Image Segmentation&lt;/li&gt;
    &lt;ul style=&#34;list-style-type:square;&#34;&gt;
      &lt;li&gt;Providing tools for users to segment and label ROI’s on an image&lt;/li&gt;
    &lt;/ul&gt;
  &lt;li&gt;Visualization&lt;/li&gt;
    &lt;ul style=&#34;list-style-type:square;&#34;&gt;
      &lt;li&gt;Developing GUI&lt;/li&gt;
      &lt;li&gt;Displaying Graphs, Images, Tables, and DICOM Metadata&lt;/li&gt;
    &lt;/ul&gt;
  &lt;li&gt;Image Classification&lt;/li&gt;
    &lt;ul style=&#34;list-style-type:square;&#34;&gt;
      &lt;li&gt;Training a CNN to classify MRI scans according to anatomical level in the brain&lt;/li&gt;
    &lt;/ul&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;packages&#34;&gt;Packages&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;PyQt5&lt;/li&gt;
  &lt;li&gt;NumPy&lt;/li&gt;
  &lt;li&gt;Pandas&lt;/li&gt;
  &lt;li&gt;PyQtGraph&lt;/li&gt;
  &lt;li&gt;PIL&lt;/li&gt;
  &lt;li&gt;CV2&lt;/li&gt;
  &lt;li&gt;Torch&lt;/li&gt;
  &lt;li&gt;TorchVision&lt;/li&gt;
  &lt;li&gt;Matplotlib&lt;/li&gt;
  &lt;li&gt;Pydicom&lt;/li&gt;
&lt;/ol&gt;


&lt;/div&gt;




		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

</description>
    </item>
    
    <item>
      <title>Ranking College Football Coaches</title>
      <link>https://arsakhar.github.io/project/ncaaf-coaches/</link>
      <pubDate>Fri, 05 Jun 2020 23:32:49 -0700</pubDate>
      <guid>https://arsakhar.github.io/project/ncaaf-coaches/</guid>
      <description>&lt;div class=&#34;article-container-nav&#34;&gt;

	&lt;nav&gt;
	
		&lt;div class=&#34;sticky-scroll navtab-position nav flex-row nav-pills&#34; id=&#34;nav-tab&#34; role=&#34;tablist&#34;&gt;
			&lt;br&gt;
			
			

			
			
			

			

			&lt;a class=&#34;nav-item nav-link active&#34; id=&#34;nav-1&#34; data-toggle=&#34;tab&#34; href=&#34;#tab11&#34; role=&#34;tab&#34;
				 aria-controls=&#34;nav-home&#34; aria-selected=&#34;true&#34;&gt;Overview&lt;/a&gt;

			
			

			
			
			

			

			&lt;a class=&#34;nav-item nav-link&#34; id=&#34;nav-1&#34; data-toggle=&#34;tab&#34; href=&#34;#tab12&#34; role=&#34;tab&#34;
				 aria-controls=&#34;nav-home&#34; aria-selected=&#34;false&#34;&gt;Skills&lt;/a&gt;

			
			
		&lt;/div&gt;
	&lt;/nav&gt;

	&lt;div class=&#34;article-style &#34;&gt;
		&lt;div class=&#34;tab-content&#34; id=&#34;1&#34;&gt;
			






&lt;div class=&#34;tab-pane fade show active&#34; id=&#34;tab11&#34; role=&#34;tabpanel&#34; aria-labelledby=&#34;nav-tabName1&#34;&gt;

	&lt;h4 id=&#34;backgroundbr&#34;&gt;Background&lt;br&gt;&lt;/h4&gt;
&lt;p&gt;I’m an avid college football fan with a keen interest in data science. For my first dive into data science, I will use some basic statistics and data manipulation to evaluate coaching in college football.
&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h4 id=&#34;defining-the-problembbr&#34;&gt;Defining the Problem&lt;/b&gt;&lt;br&gt;&lt;/h4&gt;
&lt;p&gt;Football is the crown jewel and breadwinner in any collegiate athletic department. A successful football program is not only a source of revenue for the university, it is also a powerful marketing tool, as studies have shown winning to be associated with increased donations, academic reputation, and lower acceptance rates. Therefore, it’s no surprise that coaches wield significant power and lofty salaries.&lt;/p&gt;
&lt;p&gt;Coaches also carry the burden of high expectations, poor job security, and an average tenure of only 3.8 years. While the decision to hire or fire a coach is a multi-factorial process, it is primarily driven by their record. Consequently, a coach’s value, particularly with donors and fans, is inextricably tied to their performance on the field.&lt;/p&gt;
&lt;p&gt;However, wins and losses are driven by several factors, many of which are outside a coach’s control, including conference affiliation, prestige, location, historical success, and financial investment from the university. As such, a coach’s record is not the most objective way to assess their value. In this project we will set out to define an approach for evaluating coaches while minimizing the impact of these confounding factors. Let&amp;rsquo;s get started!&lt;/p&gt;
&lt;p&gt;Continue reading on Medium: &lt;a href=&#34;https://medium.com/@arsakhare87/using-data-science-to-evaluate-recruiting-and-player-development-in-college-football-a8c5c5cd447d&#34;&gt; Using Data Science to Evaluate Recruiting and Player Development in College Football &lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Code can be downloaded at: &lt;a href=&#34;https://github.com/arsakhar/NCAAF&#34;&gt;&lt;a href=&#34;https://github.com/arsakhar/NCAAF&#34;&gt;https://github.com/arsakhar/NCAAF&lt;/a&gt;&lt;/a&gt;&lt;/p&gt;


&lt;/div&gt;










&lt;div class=&#34;tab-pane fade&#34; id=&#34;tab12&#34; role=&#34;tabpanel&#34; aria-labelledby=&#34;nav-tabName2&#34;&gt;

	&lt;h4 id=&#34;technical-skills&#34;&gt;Technical Skills&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;Data Visualization&lt;/li&gt;
    &lt;ul style=&#34;list-style-type:square;&#34;&gt;
      &lt;li&gt;Histograms, scatterplots, qq plots, boxplots&lt;/li&gt;
    &lt;/ul&gt;
  &lt;li&gt;Data Scraping&lt;/li&gt;
    &lt;ul style=&#34;list-style-type:square;&#34;&gt;
      &lt;li&gt;Scraping data across 4 different websites&lt;/li&gt;
    &lt;/ul&gt;
  &lt;li&gt;Data Cleaning&lt;/li&gt;
    &lt;ul style=&#34;list-style-type:square;&#34;&gt;
      &lt;li&gt;Removing empty rows in dataframe&lt;/li&gt;
      &lt;li&gt;Removing non-numeric / nan rows in dataframe&lt;/li&gt;
      &lt;li&gt;Filtering dataframe by a specific keyword or attribute&lt;/li&gt;
    &lt;/ul&gt;
  &lt;li&gt;Data Manipulation&lt;/li&gt;
    &lt;ul style=&#34;list-style-type:square;&#34;&gt;
      &lt;li&gt;Joining dataframes&lt;/li&gt;
      &lt;li&gt;Transforming values on a dataframe column&lt;/li&gt;
      &lt;li&gt;Applying a function elementwise on a dataframe column&lt;/li&gt;
      &lt;li&gt;Filtering dataframe based on a specific attribute or keyword&lt;/li&gt;
      &lt;li&gt;Aggregating on a dataframe column (standard deviation, mean, min, max, sum, count)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;li&gt;Statistical Analysis&lt;/li&gt;
    &lt;ul style=&#34;list-style-type:square;&#34;&gt;
      &lt;li&gt;Shapiro-Wilks test for normality&lt;/li&gt;
      &lt;li&gt;Kruskal-Wallis non-parametric test for group differences&lt;/li&gt;
      &lt;li&gt;Dunn post-hoc testing for pairwise comparisons&lt;/li&gt;
      &lt;li&gt;Box-cox for transforming skewed distribution to a gaussian&lt;/li&gt;
    &lt;/ul&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;packages&#34;&gt;Packages&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;Beautiful Soup&lt;/li&gt;
  &lt;li&gt;Scipy&lt;/li&gt;
  &lt;li&gt;Matplotlib&lt;/li&gt;
  &lt;li&gt;Pandas&lt;/li&gt;
  &lt;li&gt;Numpy&lt;/li&gt;
  &lt;li&gt;Scikit&lt;/li&gt;
  &lt;li&gt;StatsModels&lt;/li&gt;
&lt;/ol&gt;


&lt;/div&gt;




		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

</description>
    </item>
    
    <item>
      <title>Sal&#39;s Sanctuary</title>
      <link>https://arsakhar.github.io/project/sals-sanctuary/</link>
      <pubDate>Fri, 05 Jun 2020 22:19:19 -0700</pubDate>
      <guid>https://arsakhar.github.io/project/sals-sanctuary/</guid>
      <description>&lt;h3 id=&#34;overview&#34;&gt;Overview&lt;/h3&gt;
&lt;p&gt;The first in a trilogy of virtual reality exergames designed to enhance brain health. Your adventure begins as a rookie ranger at Sal&amp;rsquo;s Sanctuary, a nature reserve for animals set in an urban environment. The animal&amp;rsquo;s have escaped the sanctuary and you are tasked with locating and returning them safely. Your selective attention and spatial navigation abilities will be tested each time you conduct a rescue mission.&lt;/p&gt;
&lt;p&gt;You are assigned to one route each day and will be required to make at least 4 search and rescue trips along this route. Once an animal is located, you will pick it up and bring it back to the gates of the sanctuary before starting your next search and rescue. You are also required to pick up any food along the route that is associated with the diet of the animal you have rescued.&lt;/p&gt;
&lt;p&gt;For the first two rescue missions, we will provide visual guidance to help you learn the route. After 2 rescue missions, you are required to remember the route using only the landmarks and environment as your guidance. At the beginning of each new day, prior to starting your 4 rescue missions, you will be required to remember and navigate the route from the previous day. The difficulty of your routes will increase and the routes will get longer as you start rescuing animals located farther away from the sanctuary.&lt;/p&gt;
&lt;h3 id=&#34;video&#34;&gt;Video&lt;/h3&gt;
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/kI0bbrvH4hU&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;iframe&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Underwater Adventures</title>
      <link>https://arsakhar.github.io/project/underwater-adventures/</link>
      <pubDate>Fri, 05 Jun 2020 21:05:12 -0700</pubDate>
      <guid>https://arsakhar.github.io/project/underwater-adventures/</guid>
      <description>&lt;h3 id=&#34;overview&#34;&gt;Overview&lt;/h3&gt;
&lt;p&gt;This is the third in our trilogy of virtual reality exergames. After conquering the land, you now turn your attention to the sea. Sal plans to build a marine sanctuary and he needs your help. On this adventure, you will take pictures and collect objects that will inspire the underwater sanctuary. You will start by exploring the island and collecting the equipment necessary to begin your descent into the ocean. Sal is planning on sending you pretty deep &amp;ndash; you didn&amp;rsquo;t hear it from me, but I heard he has some secret information on the lost city of Atlantis. We shouldn&amp;rsquo;t speculate, though.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Stay tuned for more to come&amp;hellip;&lt;/b&gt;&lt;/p&gt;
&lt;h3 id=&#34;video&#34;&gt;Video&lt;/h3&gt;
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/UGuaEmGRSRE&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;iframe&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Wildlife Enclosure</title>
      <link>https://arsakhar.github.io/project/wildlife-enclosure/</link>
      <pubDate>Fri, 05 Jun 2020 21:05:12 -0700</pubDate>
      <guid>https://arsakhar.github.io/project/wildlife-enclosure/</guid>
      <description>&lt;h3 id=&#34;overview&#34;&gt;Overview&lt;/h3&gt;
&lt;p&gt;This is the second in our trilogy of virtual reality exergames. You start the game as the chief ranger at Sal&amp;rsquo;s Wildlife Enclosure, a nature reserve for animals set in a savannah, jungle, safari, and aviary. You are tasked with taking care of all the animal&amp;rsquo;s in the wildlife enclosure. Your missions consist of feeding animals, treating injured animals at the vet clinic, putting out fires, and repairing broken equipment. There are two primary cognitive skills assessed each day you bike around the enclosure to complete your missions: selective attention and spatial navigation.&lt;/p&gt;
&lt;p&gt;For the selective attention task, you are required to pick up objects associated with your mission. For example, if you are putting out a fire, you will be required to pickup axes and fire extinguishers on the way. For spatial navigation, you are assigned to one route each day. You will complete 4 missions, each time biking along the same route. For the first two missions, we will provide arrows to help you learn the route. After 2 missions, you are required to remember the route using only the landmarks and environment as cues. At the beginning of each day, prior to starting your 4 missions, you will be required to remember and navigate the route from the previous day. The difficulty of your routes will increase and the routes will get longer as you start moving towards the perimeter of the wildlife enclosure.&lt;/p&gt;
&lt;h3 id=&#34;video&#34;&gt;Video&lt;/h3&gt;
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/YLXAhpwOIpM&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;iframe&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Cycling and Spatial Navigation in an Enriched, Immersive 3D Virtual Park Environment: A Feasibility Study in Younger and Older Adults</title>
      <link>https://arsakhar.github.io/publication/frontiers-aging-neuroscience/</link>
      <pubDate>Sat, 23 May 2020 23:20:29 -0700</pubDate>
      <guid>https://arsakhar.github.io/publication/frontiers-aging-neuroscience/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Assessing test–retest reliability of phase contrast MRI for measuring cerebrospinal fluid and cerebral blood flow dynamics</title>
      <link>https://arsakhar.github.io/publication/magnetic-resonance-medicine/</link>
      <pubDate>Sat, 23 May 2020 23:13:19 -0700</pubDate>
      <guid>https://arsakhar.github.io/publication/magnetic-resonance-medicine/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Unity3D - Performance Optimization</title>
      <link>https://arsakhar.github.io/blog/game-optimization/</link>
      <pubDate>Thu, 08 Aug 2019 22:42:40 -0700</pubDate>
      <guid>https://arsakhar.github.io/blog/game-optimization/</guid>
      <description>&lt;div class=&#34;article-container-nav&#34;&gt;

	&lt;nav&gt;
	
		&lt;div class=&#34;sticky-scroll navtab-position nav flex-row nav-pills&#34; id=&#34;nav-tab&#34; role=&#34;tablist&#34;&gt;
			&lt;br&gt;
			
			

			
			
			

			

			&lt;a class=&#34;nav-item nav-link active&#34; id=&#34;nav-1&#34; data-toggle=&#34;tab&#34; href=&#34;#tab11&#34; role=&#34;tab&#34;
				 aria-controls=&#34;nav-home&#34; aria-selected=&#34;true&#34;&gt;Background&lt;/a&gt;

			
			

			
			
			

			

			&lt;a class=&#34;nav-item nav-link&#34; id=&#34;nav-1&#34; data-toggle=&#34;tab&#34; href=&#34;#tab12&#34; role=&#34;tab&#34;
				 aria-controls=&#34;nav-home&#34; aria-selected=&#34;false&#34;&gt;Garbage Collection&lt;/a&gt;

			
			

			
			
			

			

			&lt;a class=&#34;nav-item nav-link&#34; id=&#34;nav-1&#34; data-toggle=&#34;tab&#34; href=&#34;#tab13&#34; role=&#34;tab&#34;
				 aria-controls=&#34;nav-home&#34; aria-selected=&#34;false&#34;&gt;Polygon Count&lt;/a&gt;

			
			

			
			
			

			

			&lt;a class=&#34;nav-item nav-link&#34; id=&#34;nav-1&#34; data-toggle=&#34;tab&#34; href=&#34;#tab14&#34; role=&#34;tab&#34;
				 aria-controls=&#34;nav-home&#34; aria-selected=&#34;false&#34;&gt;Draw Calls&lt;/a&gt;

			
			

			
			
			

			

			&lt;a class=&#34;nav-item nav-link&#34; id=&#34;nav-1&#34; data-toggle=&#34;tab&#34; href=&#34;#tab15&#34; role=&#34;tab&#34;
				 aria-controls=&#34;nav-home&#34; aria-selected=&#34;false&#34;&gt;Camera Culling&lt;/a&gt;

			
			

			
			
			

			

			&lt;a class=&#34;nav-item nav-link&#34; id=&#34;nav-1&#34; data-toggle=&#34;tab&#34; href=&#34;#tab16&#34; role=&#34;tab&#34;
				 aria-controls=&#34;nav-home&#34; aria-selected=&#34;false&#34;&gt;Static Batching&lt;/a&gt;

			
			

			
			
			

			

			&lt;a class=&#34;nav-item nav-link&#34; id=&#34;nav-1&#34; data-toggle=&#34;tab&#34; href=&#34;#tab17&#34; role=&#34;tab&#34;
				 aria-controls=&#34;nav-home&#34; aria-selected=&#34;false&#34;&gt;References&lt;/a&gt;

			
			
		&lt;/div&gt;
	&lt;/nav&gt;

	&lt;div class=&#34;article-style &#34;&gt;
		&lt;div class=&#34;tab-content&#34; id=&#34;1&#34;&gt;
			







&lt;div class=&#34;tab-pane fade show active&#34; id=&#34;tab11&#34; role=&#34;tabpanel&#34; aria-labelledby=&#34;nav-tabName1&#34;&gt;

	&lt;h3 id=&#34;background&#34;&gt;Background&lt;/h3&gt;
&lt;p&gt;The majority of VR headsets on the market use a 90 Hz refresh rate, such that the display on the headset is refreshed every 11 ms. Dropped frames will occur if the computer is unable to render an image within that time frame. API’s employ several techniques to account for dropped frames. These include timewarp, asynchronous timewarp, interleaved reprojection, motion smoothing, and positional timewarp.&lt;sup&gt;4&lt;/sup&gt; While these techniques account for dropped frames to a certain extent, a poorly optimized game will still result in jittery views which can be quite nauseogenic. Therefore, performance optimization is a key component of VR game development. In this article, I will provide a brief overview of the most common techniques used to optimize performance. I will also provide links that provide a more in-depth discussion of each technique. Please note that this is not an exhaustive list of performance tips, rather a list of low hanging fruit that can lead to substantial improvements in performance.

&lt;/div&gt;











&lt;div class=&#34;tab-pane fade&#34; id=&#34;tab12&#34; role=&#34;tabpanel&#34; aria-labelledby=&#34;nav-tabName2&#34;&gt;

	&lt;h3 id=&#34;garbage-collection&#34;&gt;Garbage Collection&lt;/h3&gt;
&lt;p&gt;Garbage collection (GC) is a form of automated memory management.&lt;sup&gt;1&lt;/sup&gt; There are two types of memory allocation: heap and stack. Furthermore, there are two data types: primitive and non-primitive.&lt;sup&gt;3&lt;/sup&gt; Primitive data types include the following: bool, bytes, short, int, long, float, double, decimal, and char. All primitive data type values are stored in stack memory. Non-primitive data types are objects and include the following: class, struct, enum, array, and string. Non-primitive data types are known as reference types, as the stack memory only contains a reference to the value. The reference in the stack points to an object located in heap memory that contains the value . GC only track objects (non-primitive data types) that occupy space in heap memory.&lt;sup&gt;2&lt;/sup&gt; The job of GC is to free memory when the object is no longer being referenced in the stack memory.&lt;/p&gt;
&lt;p&gt;Unity uses the Boehm–Demers–Weiser GC5, which is a type of stop-the-world GC. This means that when GC is required, code execution will stop until the GC process is complete. Depending on the frequency of GC, this can result in dropped frames and significantly affect the smoothness of gameplay. The figure below illustrates code that minimizes garbage collection (GoodExample) and unnecessarily increases garbage collection (BadExample).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://arsakhar.github.io/img/game-optimization/garbage-collect.png&#34; alt=&#34;Example image&#34;&gt;&lt;/p&gt;
&lt;p&gt;In the bad example, we are instantiating a new WaitForSeconds routine every second. This results in a heap memory allocation every time an instance of WaitForSeconds is created. Each heap memory allocation is going to trigger a garbage collection. To minimize garbage collection, a single instance of WaitForSeconds can be used used if the wait period is the same each time.&lt;/p&gt;
&lt;p&gt;Further Reading:&lt;br&gt;
&lt;a href=&#34;https://jacksondunstan.com/articles/2981&#34;&gt;https://jacksondunstan.com/articles/2981&lt;/a&gt;
&lt;a href=&#34;http://blog.tochasstudios.com/2015/11/cache-coroutines.html&#34;&gt;http://blog.tochasstudios.com/2015/11/cache-coroutines.html&lt;/a&gt;
&lt;a href=&#34;https://forum.unity.com/threads/c-coroutine-waitforseconds-garbage-collection-tip.224878/&#34;&gt;https://forum.unity.com/threads/c-coroutine-waitforseconds-garbage-collection-tip.224878/&lt;/a&gt;&lt;/p&gt;


&lt;/div&gt;











&lt;div class=&#34;tab-pane fade&#34; id=&#34;tab13&#34; role=&#34;tabpanel&#34; aria-labelledby=&#34;nav-tabName3&#34;&gt;

	&lt;h3 id=&#34;polygon-count&#34;&gt;Polygon Count&lt;/h3&gt;
&lt;p&gt;The primary responsibility of the GPU is to render an image to the screen. The complexity of an image can significantly impact rendering performance. In VR, the images that are rendered are 3D meshes. Briefly, all meshes are composed of smaller units known as polygons, which can be further decomposed into triangles. Triangles consist of vertices whose positions can be stored as an array of values (x,y,z). During rendering, the GPU first uses a vertex shader to compute where the triangle should be placed on the screen and then uses a fragment shader to fill in the pixels (rasterize) within the vertices of the triangle.&lt;sup&gt;6&lt;/sup&gt; With modern GPU’s, polygon counts aren’t typically a bottleneck for performance. However, it’s still good practice for developers to simplify meshes in situations where detailed renderings aren’t needed. Blender is a free 3D modeling program that has the ability to simplify a mesh using the decimate function.&lt;/p&gt;
&lt;p&gt;Further Reading:&lt;br&gt;
&lt;a href=&#34;http://software.intel.com/en-us/articles/model-for-real-time-beyond-counting-polygons/&#34;&gt;http://software.intel.com/en-us/articles/model-for-real-time-beyond-counting-polygons/&lt;/a&gt;&lt;/p&gt;


&lt;/div&gt;











&lt;div class=&#34;tab-pane fade&#34; id=&#34;tab14&#34; role=&#34;tabpanel&#34; aria-labelledby=&#34;nav-tabName4&#34;&gt;

	&lt;h3 id=&#34;draw-calls&#34;&gt;Draw Calls&lt;/h3&gt;
&lt;p&gt;A draw call is an instruction sent from the CPU to the GPU to render an image to the screen. An excessive number of draw calls can bottleneck the CPU if it is unable to push all draw call instructions to the GPU within that frame. In Unity, a draw call is required any time the GPU has to render a material. Multiple materials can be assigned to a single mesh, while a single diffuse texture is typically assigned to each material. A mesh consisting of 4 materials would require 4 separate draw calls from the CPU. The number of draw calls can be minimized by combining multiple meshes into a single mesh and applying a single material to that mesh. The use of a single material is possible through texture atlases, which map out how a texture is laid onto a material. MeshBaker on the Unity Asset Store is a popular asset that allows user’s to combine meshes and create texture atlases.&lt;sup&gt;7&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;Further Reading:&lt;br&gt;
&lt;a href=&#34;https://medium.com/@toncijukic/draw-calls-in-a-nutshell-597330a85381&#34;&gt;https://medium.com/@toncijukic/draw-calls-in-a-nutshell-597330a85381&lt;/a&gt;&lt;/p&gt;


&lt;/div&gt;











&lt;div class=&#34;tab-pane fade&#34; id=&#34;tab15&#34; role=&#34;tabpanel&#34; aria-labelledby=&#34;nav-tabName5&#34;&gt;

	&lt;h3 id=&#34;camera-culling&#34;&gt;Camera Culling&lt;/h3&gt;
&lt;p&gt;By default, the camera in the game will render everything within its FOV. However, this is not always necessary as the user’s viewing depth is typically limited by vegetation, buildings, and other objects within the scene. Consider setting a culling distance such that any objects past that distance are not rendered. Game objects can even be assigned to different layers and a separate culling distance can be used for each layer. For example, flowers may require a shorter culling distance while larger landmarks may require a larger culling distance.&lt;/p&gt;
&lt;p&gt;Further Reading:&lt;br&gt;
&lt;a href=&#34;https://docs.unity3d.com/ScriptReference/Camera-layerCullDistances.html&#34;&gt;https://docs.unity3d.com/ScriptReference/Camera-layerCullDistances.html&lt;/a&gt;&lt;/p&gt;


&lt;/div&gt;











&lt;div class=&#34;tab-pane fade&#34; id=&#34;tab16&#34; role=&#34;tabpanel&#34; aria-labelledby=&#34;nav-tabName6&#34;&gt;

	&lt;h3 id=&#34;static-batching&#34;&gt;Static Batching&lt;/h3&gt;
&lt;p&gt;For any object that isn’t moving in the environment, enable static batching. This combines all meshes that have the same material into 1 and renders it in 1 draw call. The negative is increased memory overhead. However, the advantage of this over consolidating into 1 mesh is that you can still cull each object individually.

&lt;/div&gt;











&lt;div class=&#34;tab-pane fade&#34; id=&#34;tab17&#34; role=&#34;tabpanel&#34; aria-labelledby=&#34;nav-tabName7&#34;&gt;

	&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;“Garbage collection (computer science) – Wikipedia.” [Online]. Available: &lt;a href=&#34;https://en.wikipedia.org/wiki/Garbage_collection_(computer_science)&#34;&gt;https://en.wikipedia.org/wiki/Garbage_collection_(computer_science)&lt;/a&gt;. [Accessed: 19-Jun-2019].&lt;/li&gt;
&lt;li&gt;“Feature Preview: Incremental Garbage Collection – Unity Blog.” [Online]. Available: &lt;a href=&#34;https://blogs.unity3d.com/2018/11/26/feature-preview-incremental-garbage-collection/&#34;&gt;https://blogs.unity3d.com/2018/11/26/feature-preview-incremental-garbage-collection/&lt;/a&gt;. [Accessed: 19-Jun-2019].&lt;/li&gt;
&lt;li&gt;“C# Variables: Primitive and Non-primitive Types.” [Online]. Available: &lt;a href=&#34;http://www.jeremyshanks.com/c-variables-primitive-nonprimitive-types/&#34;&gt;http://www.jeremyshanks.com/c-variables-primitive-nonprimitive-types/&lt;/a&gt;. [Accessed: 19-Jun-2019].&lt;/li&gt;
&lt;li&gt;D. Heaney, D. Jagneaux, J. Feltham, and J. Feltham, “VR Timewarp, Spacewarp, Reprojection, And Motion Smoothing Explained,” UploadVR, 18-Jan-2019. [Online]. Available: &lt;a href=&#34;https://uploadvr.com/reprojection-explained/&#34;&gt;https://uploadvr.com/reprojection-explained/&lt;/a&gt;. [Accessed: 15-Jul-2019]&lt;/li&gt;
&lt;li&gt;A garbage collector for C and C++. (2019). Retrieved from &lt;a href=&#34;https://www.hboehm.info/gc/&#34;&gt;https://www.hboehm.info/gc/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Eskil_steenberg. “Model for Real Time-Beyond Counting Polygons.” Intel® Software, Intel, 15 Dec. 2018, software.intel.com/en-us/articles/model-for-real-time-beyond-counting-polygons.&lt;/li&gt;
&lt;li&gt;Digital Opus, digitalopus.ca/site/mesh-baker/.&lt;/li&gt;
&lt;/ol&gt;


&lt;/div&gt;




		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

</description>
    </item>
    
    <item>
      <title>Locomotion in Virtual Reality</title>
      <link>https://arsakhar.github.io/blog/commercial-locomotion/</link>
      <pubDate>Sun, 03 Feb 2019 15:30:47 -0700</pubDate>
      <guid>https://arsakhar.github.io/blog/commercial-locomotion/</guid>
      <description>&lt;div class=&#34;article-container-nav&#34;&gt;

	&lt;nav&gt;
	
		&lt;div class=&#34;sticky-scroll navtab-position nav flex-row nav-pills&#34; id=&#34;nav-tab&#34; role=&#34;tablist&#34;&gt;
			&lt;br&gt;
			
			

			
			
			

			

			&lt;a class=&#34;nav-item nav-link active&#34; id=&#34;nav-1&#34; data-toggle=&#34;tab&#34; href=&#34;#tab11&#34; role=&#34;tab&#34;
				 aria-controls=&#34;nav-home&#34; aria-selected=&#34;true&#34;&gt;Background&lt;/a&gt;

			
			

			
			
			

			

			&lt;a class=&#34;nav-item nav-link&#34; id=&#34;nav-1&#34; data-toggle=&#34;tab&#34; href=&#34;#tab12&#34; role=&#34;tab&#34;
				 aria-controls=&#34;nav-home&#34; aria-selected=&#34;false&#34;&gt;Treadmills&lt;/a&gt;

			
			

			
			
			

			

			&lt;a class=&#34;nav-item nav-link&#34; id=&#34;nav-1&#34; data-toggle=&#34;tab&#34; href=&#34;#tab13&#34; role=&#34;tab&#34;
				 aria-controls=&#34;nav-home&#34; aria-selected=&#34;false&#34;&gt;Bikes&lt;/a&gt;

			
			

			
			
			

			

			&lt;a class=&#34;nav-item nav-link&#34; id=&#34;nav-1&#34; data-toggle=&#34;tab&#34; href=&#34;#tab14&#34; role=&#34;tab&#34;
				 aria-controls=&#34;nav-home&#34; aria-selected=&#34;false&#34;&gt;References&lt;/a&gt;

			
			
		&lt;/div&gt;
	&lt;/nav&gt;

	&lt;div class=&#34;article-style &#34;&gt;
		&lt;div class=&#34;tab-content&#34; id=&#34;1&#34;&gt;
			






&lt;div class=&#34;tab-pane fade show active&#34; id=&#34;tab11&#34; role=&#34;tabpanel&#34; aria-labelledby=&#34;nav-tabName1&#34;&gt;

	&lt;h3 id=&#34;background&#34;&gt;Background&lt;/h3&gt;
&lt;p&gt;Developing games that require locomotion is a significant challenge in virtual reality, as freedom of movement is restricted by cables on a tethered headset and transmitter signal strength on a wireless headset. Furthermore, movement is also constrained to the dimensions of the physical space in which movement is occurring.&lt;/p&gt;
&lt;p&gt;To circumvent this problem, companies and research labs have developed solutions that allow user’s to move through a virtual environment while remaining stationary. In this post, i’ll highlight two of the most popular locomotion techniques in VR: treadmills and stationary exercise bikes.&lt;/p&gt;


&lt;/div&gt;










&lt;div class=&#34;tab-pane fade&#34; id=&#34;tab12&#34; role=&#34;tabpanel&#34; aria-labelledby=&#34;nav-tabName2&#34;&gt;

	&lt;h3 id=&#34;treadmills&#34;&gt;Treadmills&lt;/h3&gt;
&lt;p&gt;Virtuix ( &lt;a href=&#34;https://www.virtuix.com/&#34;&gt;https://www.virtuix.com/&lt;/a&gt; ) was one of the first companies to tread into the space of VR locomotion with a kickstarter campaign in June 2013.5 The Virtuix Omni is an omni-directional treadmill that allows users 360 degrees freedom of movement. A brief description of the system is below:&lt;/p&gt;
&lt;p&gt;“To use the Omni system, players wear special overshoes which stretch to fit over normal footwear. The player is held in place by a comfortable but firm harness. The HTC Vive VR headset is dropped down from above each player, so no wires get in the way to disrupt the VR illusion. The players’ feet slide along the plastic dish under their feet, while inside the simulation, they move forward, providing the unique full immersion of free roam VR in a much, much smaller space.”&lt;sup&gt;1&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://arsakhar.github.io/img/commercial-locomotion/omniverse.png&#34; alt=&#34;Example image&#34;&gt;&lt;/p&gt;
&lt;figcaption&gt;https://www.virtuix.com/virtuix-omni-rides-vr-esports-explosion-to-one-million-plays/&lt;/figcaption&gt;
&lt;p&gt;Other VR treadmills include:&lt;sup&gt;2,3,4&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;KatVR (&lt;a href=&#34;https://katvr.com/&#34;&gt;https://katvr.com/&lt;/a&gt;)&lt;br&gt;
Cyberith Virtualizer (&lt;a href=&#34;https://www.cyberith.com/&#34;&gt;https://www.cyberith.com/&lt;/a&gt;)&lt;br&gt;
Omnideck (&lt;a href=&#34;http://omnifinity.se/&#34;&gt;http://omnifinity.se/&lt;/a&gt;)&lt;br&gt;
Infinadeck (&lt;a href=&#34;https://www.infinadeck.com/&#34;&gt;https://www.infinadeck.com/&lt;/a&gt;)&lt;br&gt;
The Aperium Pod (&lt;a href=&#34;http://aperiumreality.com/index.php/en/home/&#34;&gt;http://aperiumreality.com/index.php/en/home/&lt;/a&gt;)&lt;br&gt;
Spacewalker VR (&lt;a href=&#34;http://www.spacewalkervr.com/&#34;&gt;http://www.spacewalkervr.com/&lt;/a&gt;)&lt;br&gt;&lt;/p&gt;
&lt;p&gt;The KatVR, Cyberith Virtualizer, Aperium Pod, and Spacewalk VR are considered “slidemills”, as they require the user to slide their feet against a platform to engage in locomotion. The omnideck and infinideck are equipped with a variable-speed treadmill platform that utilizes positional feedback to ensure the user is always located near the center of the platform.&lt;/p&gt;


&lt;/div&gt;










&lt;div class=&#34;tab-pane fade&#34; id=&#34;tab13&#34; role=&#34;tabpanel&#34; aria-labelledby=&#34;nav-tabName3&#34;&gt;

	&lt;h3 id=&#34;stationary-exercise-bikes&#34;&gt;Stationary Exercise Bikes&lt;/h3&gt;
&lt;p&gt;In 2016, VirZoom (&lt;a href=&#34;https://www.virzoom.com/&#34;&gt;https://www.virzoom.com/&lt;/a&gt;) released the first stationary exercise bike designed to support locomotion in VR. The bike (pictured below) is equipped with a number of buttons on the handlebars, making it well-suited for gaming and exercise.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://arsakhar.github.io/img/commercial-locomotion/vir-zoom.png&#34; alt=&#34;Example image&#34;&gt;&lt;/p&gt;
&lt;figcaption&gt;https://www.roadtovr.com/virzoom-closes-5-5m-seed-funding-develop-second-generation-vr-bike-kit/&lt;/figcaption&gt;
Other VR bikes include:
&lt;p&gt;NordicTrack VR (&lt;a href=&#34;https://www.cnet.com/news/nordictracks-vr-fitness-bike-wore-me-out-at-ces/&#34;&gt;https://www.cnet.com/news/nordictracks-vr-fitness-bike-wore-me-out-at-ces/&lt;/a&gt;)&lt;/p&gt;


&lt;/div&gt;










&lt;div class=&#34;tab-pane fade&#34; id=&#34;tab14&#34; role=&#34;tabpanel&#34; aria-labelledby=&#34;nav-tabName4&#34;&gt;

	&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://www.virtuix.com/virtuix-omni-rides-vr-esports-explosion-to-one-million-plays/&#34;&gt;https://www.virtuix.com/virtuix-omni-rides-vr-esports-explosion-to-one-million-plays/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://packet39.com/blog/2018/03/25/vr-treadmill-overview-march-2018/&#34;&gt;https://packet39.com/blog/2018/03/25/vr-treadmill-overview-march-2018/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.vrfitnessinsider.com/vr-omnidirectional-treadmills-making-gains-towards-full-immersion-and-cardio/&#34;&gt;https://www.vrfitnessinsider.com/vr-omnidirectional-treadmills-making-gains-towards-full-immersion-and-cardio/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.aniwaa.com/blog/best-vr-treadmills-vr-slidemills/&#34;&gt;https://www.aniwaa.com/blog/best-vr-treadmills-vr-slidemills/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Virtuix_Omni&#34;&gt;https://en.wikipedia.org/wiki/Virtuix_Omni&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;


&lt;/div&gt;




		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

</description>
    </item>
    
    <item>
      <title>Meningioma Classification using Machine Learning</title>
      <link>https://arsakhar.github.io/project/meningioma/</link>
      <pubDate>Sun, 03 Feb 2019 15:30:47 -0700</pubDate>
      <guid>https://arsakhar.github.io/project/meningioma/</guid>
      <description>&lt;div class=&#34;article-container-nav&#34;&gt;

	&lt;nav&gt;
	
		&lt;div class=&#34;sticky-scroll navtab-position nav flex-row nav-pills&#34; id=&#34;nav-tab&#34; role=&#34;tablist&#34;&gt;
			&lt;br&gt;
			
			

			
			
			

			

			&lt;a class=&#34;nav-item nav-link active&#34; id=&#34;nav-1&#34; data-toggle=&#34;tab&#34; href=&#34;#tab11&#34; role=&#34;tab&#34;
				 aria-controls=&#34;nav-home&#34; aria-selected=&#34;true&#34;&gt;Objective&lt;/a&gt;

			
			

			
			
			

			

			&lt;a class=&#34;nav-item nav-link&#34; id=&#34;nav-1&#34; data-toggle=&#34;tab&#34; href=&#34;#tab12&#34; role=&#34;tab&#34;
				 aria-controls=&#34;nav-home&#34; aria-selected=&#34;false&#34;&gt;Data Acquisition&lt;/a&gt;

			
			

			
			
			

			

			&lt;a class=&#34;nav-item nav-link&#34; id=&#34;nav-1&#34; data-toggle=&#34;tab&#34; href=&#34;#tab13&#34; role=&#34;tab&#34;
				 aria-controls=&#34;nav-home&#34; aria-selected=&#34;false&#34;&gt;Pre-Processing&lt;/a&gt;

			
			

			
			
			

			

			&lt;a class=&#34;nav-item nav-link&#34; id=&#34;nav-1&#34; data-toggle=&#34;tab&#34; href=&#34;#tab14&#34; role=&#34;tab&#34;
				 aria-controls=&#34;nav-home&#34; aria-selected=&#34;false&#34;&gt;Training&lt;/a&gt;

			
			

			
			
			

			

			&lt;a class=&#34;nav-item nav-link&#34; id=&#34;nav-1&#34; data-toggle=&#34;tab&#34; href=&#34;#tab15&#34; role=&#34;tab&#34;
				 aria-controls=&#34;nav-home&#34; aria-selected=&#34;false&#34;&gt;Results&lt;/a&gt;

			
			

			
			
			

			

			&lt;a class=&#34;nav-item nav-link&#34; id=&#34;nav-1&#34; data-toggle=&#34;tab&#34; href=&#34;#tab16&#34; role=&#34;tab&#34;
				 aria-controls=&#34;nav-home&#34; aria-selected=&#34;false&#34;&gt;Discussion&lt;/a&gt;

			
			

			
			
			

			

			&lt;a class=&#34;nav-item nav-link&#34; id=&#34;nav-1&#34; data-toggle=&#34;tab&#34; href=&#34;#tab17&#34; role=&#34;tab&#34;
				 aria-controls=&#34;nav-home&#34; aria-selected=&#34;false&#34;&gt;References&lt;/a&gt;

			
			

			
			
			

			

			&lt;a class=&#34;nav-item nav-link&#34; id=&#34;nav-1&#34; data-toggle=&#34;tab&#34; href=&#34;#tab18&#34; role=&#34;tab&#34;
				 aria-controls=&#34;nav-home&#34; aria-selected=&#34;false&#34;&gt;Skills&lt;/a&gt;

			
			
		&lt;/div&gt;
	&lt;/nav&gt;

	&lt;div class=&#34;article-style &#34;&gt;
		&lt;div class=&#34;tab-content&#34; id=&#34;1&#34;&gt;
			






&lt;div class=&#34;tab-pane fade show active&#34; id=&#34;tab11&#34; role=&#34;tabpanel&#34; aria-labelledby=&#34;nav-tabName1&#34;&gt;

	&lt;h4 id=&#34;problem-statement&#34;&gt;Problem Statement&lt;/h4&gt;
&lt;p&gt;Meningiomas are tumors that form on the meninges, a membrane that covers the brain and spinal cord. The current standard of treatment is a craniotomy where the skull is opened to provide access to the tumor. Recent technological advances have allowed meningioma’s to be resected using minimally invasive endoscopic or key-hole surgical approaches.&lt;sup&gt;1&lt;/sup&gt; The selection of patients for these minimally invasive surgeries are based on several tumor characteristics such as pathology, vascularity, and invasiveness.&lt;sup&gt;1&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;One key characteristic that dictates ease of operation is tumor consistency, defined as texture or firmness.&lt;sup&gt;1&lt;/sup&gt; Tumor consistency, which can only be measured after surgical resection, is graded on a 5-point hardness scale (1-softest, 5-hardest).&lt;sup&gt;1,2&lt;/sup&gt; Training a machine learning model to classify a tumor according to its hardness using neuroimaging data could help physicians determine if a patient is a candidate for minimally invasive surgery.&lt;/p&gt;
&lt;h4 id=&#34;objective&#34;&gt;Objective&lt;/h4&gt;
&lt;p&gt;To train a convolutional neural network to classify meningioma tumors based on hardness ratings.&lt;/p&gt;
&lt;p&gt;Code can be downloaded at: &lt;a href=&#34;https://github.com/arsakhar/ML-Meningioma-Classification&#34;&gt;&lt;a href=&#34;https://github.com/arsakhar/ML-Meningioma-Classification&#34;&gt;https://github.com/arsakhar/ML-Meningioma-Classification&lt;/a&gt;&lt;/a&gt;&lt;/p&gt;


&lt;/div&gt;










&lt;div class=&#34;tab-pane fade&#34; id=&#34;tab12&#34; role=&#34;tabpanel&#34; aria-labelledby=&#34;nav-tabName2&#34;&gt;

	&lt;h4 id=&#34;data-acquisition&#34;&gt;Data Acquisition&lt;/h4&gt;
&lt;p&gt;MRI scans were acquired on 85 patients across several hospitals. For each patient, an ADC, T2 flair, T1, T1 with contrast (T1c), and T2 scan were acquired. A lesion mask was manually created by the physician after image acquisition. Resected meningioma’s were manually labeled using a 0-3 hardness scale by expert raters.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://arsakhar.github.io/project/meningioma/data-acquisition.png&#34; /&gt;&lt;/img&gt;&lt;/p&gt;


&lt;/div&gt;










&lt;div class=&#34;tab-pane fade&#34; id=&#34;tab13&#34; role=&#34;tabpanel&#34; aria-labelledby=&#34;nav-tabName3&#34;&gt;

	&lt;h4 id=&#34;pre-processing&#34;&gt;Pre-Processing&lt;/h4&gt;
&lt;p&gt;A supervised learning task for multi-class classification was considered based on the provided labels and discrete grading scale. A convolutional neural network classifier was chosen as the inputs were images.&lt;/p&gt;
&lt;p&gt;The bar chart below shows the distribution of meningioma classes for the acquired data. Class 0 and 1 were the lowest and highest frequency, respectively. Overall, the dataset was highly imbalanced between classes 1, 3 and 1,2. Moreover, only a limited sample of 425 scans (85 patients and 5 scans per patient) were available for training the model.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://arsakhar.github.io/project/meningioma/data-exploration.png&#34; /&gt;&lt;/img&gt;&lt;/p&gt;
&lt;p&gt;One issue with the acquired data was that the dimensions of the scans were consistent within a subject but differed between subjects. Briefly, an MRI scan is a 3D volume of height, width, and depth where depth represents the number of slices.&lt;/p&gt;
&lt;p&gt;To ensure a consistent input shape into the CNN, each scan was resampled to a size of 256x256xZ. Z was set to 256 if the image had less than 256 slices. Otherwise, the original number of slices was retained.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://arsakhar.github.io/project/meningioma/pre-processing-1.png&#34; /&gt;&lt;/img&gt;&lt;/p&gt;
&lt;p&gt;To increase the number of available training samples, each scan was decomposed into its individual slices.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://arsakhar.github.io/project/meningioma/pre-processing-2.png&#34; /&gt;&lt;/img&gt;&lt;/p&gt;
&lt;p&gt;The figure below illustrates multiple slices across a single scan.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://arsakhar.github.io/project/meningioma/pre-processing-3.png&#34; /&gt;&lt;/img&gt;&lt;/p&gt;
&lt;p&gt;Each individual slice was then re-assigned the original class label only if it contained the lesion based on the lesion mask. Slices that did not contain a lesion were not included in training the model. Decomposing and re-assigning class labels increased the accuracy of the label assignments as a single label was no longer applied to an entire 3D volume.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://arsakhar.github.io/project/meningioma/pre-processing-4.png&#34; /&gt;&lt;/img&gt;&lt;/p&gt;


&lt;/div&gt;










&lt;div class=&#34;tab-pane fade&#34; id=&#34;tab14&#34; role=&#34;tabpanel&#34; aria-labelledby=&#34;nav-tabName4&#34;&gt;

	&lt;h4 id=&#34;training&#34;&gt;Training&lt;/h4&gt;
&lt;p&gt;Residual Neural Network 152 (ResNet 152) was selected as the CNN model for training. The following hyperparameters were randomly selected and evaluated using Optuna:&lt;/p&gt;
&lt;ul style=&#34;list-style-type:square;&#34;&gt;
&lt;li&gt;Optimizer – Adam, RMSprop, SGD&lt;/li&gt;
&lt;li&gt;Learning Rate – log uniform distribution, [1e-6, 1e-1]&lt;/li&gt;
&lt;li&gt;Dropout – uniform distribution, [0.1, 0.7]&lt;/li&gt;
&lt;li&gt;Batch Size – categorical, [16, 32, 64, 128]&lt;/li&gt;
&lt;li&gt;L2 Regularization – log uniform distribution, [1e-10, 1e-3]&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The remaining training parameters were set as follows:&lt;/p&gt;
&lt;ul style=&#34;list-style-type:square;&#34;&gt;
&lt;li&gt;Input Channels – 5 [t1, t1c, t2 flair, t2, adc]&lt;/li&gt;
&lt;li&gt;# Classes – 4&lt;/li&gt;
&lt;li&gt;# Epochs – 45&lt;/li&gt;
&lt;li&gt;Loss function – cross-entropy&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The cross-entropy loss function was weighted according to the distribution of classes in the dataset.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://arsakhar.github.io/project/meningioma/training-1.png&#34; /&gt;&lt;/img&gt;&lt;/p&gt;
&lt;p&gt;Two modifications were made to the original ResNet152 model. The first convolutional layer was modified to accept 5 input channels instead of 3 and the fully connected layer was modified to output probabilities for 4 classes instead of 1000.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://arsakhar.github.io/project/meningioma/training-2.png&#34; /&gt;&lt;/img&gt;&lt;/p&gt;
&lt;p&gt;The ResNet 152 model was trained using 5-fold cross validation. The folds were stratified by subject to ensure all slices associated with a single subject were constrained to a single fold. Briefly, neighboring slices within a scan are structurally similar as they are anatomically acquired a few mm apart. This problem is exacerbated in subjects where the scan is up sampled to 256 slices during preprocessing. The similarity of slices results in data leakage if the slices are spread across the training and test fold. The folds were also stratified by class label to ensure the distribution of classes in the training and test fold approximated the actual distribution of classes for the acquired data.&lt;/p&gt;
&lt;p&gt;A custom dataset class was used to load, augment, and transform the slices to tensors for input into the CNN. TorchIO, a python package for medical image preprocessing, was used for data augmentation. Briefly, both training and validation slices were normalized to a mean of zero and standard deviation of one. Training slices were also augmented with a random blur, noise, bias field, motion, spike, ghosting, affine transformations, and elastic deformations at specified probabilities. This was done to provide additional unique images for the CNN to train on in the absence of a large training dataset.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://arsakhar.github.io/project/meningioma/training-3.png&#34; /&gt;&lt;/img&gt;&lt;/p&gt;
&lt;p&gt;Each epoch consisted of a training and validation iteration. Both iterations consisted of a forward pass. Loss was calculated using the SoftMax output and target labels. The weights and bias in each layer were updated via back propagation for the training iterations. The argmax of the SoftMax output probabilities was used to calculate accuracy, defined by the proportion of correct predictions to total predictions.&lt;/p&gt;


&lt;/div&gt;










&lt;div class=&#34;tab-pane fade&#34; id=&#34;tab15&#34; role=&#34;tabpanel&#34; aria-labelledby=&#34;nav-tabName5&#34;&gt;

	&lt;h4 id=&#34;results&#34;&gt;Results&lt;/h4&gt;
&lt;p&gt;Overall, the trained CNN model performed poorly on the validation dataset across multiple sets of hyperparameters selected by Optuna. The figure below shows the training and validation loss accuracy for a single fold and set of hyperparameters. As expected for training, the loss decreased (solid black line) and accuracy (dashed black line) increased, with accuracy approaching 95% after 45 epochs. However, validation loss (solid red line) and validation accuracy (dashed red line) did not improve during training. Validation loss decreased for the first 10 epochs before increasing. The validation accuracy increased to approximately 35% after 10 epochs before decreasing to 20%. Therefore, overfitting likely occurred after the 10th epoch.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://arsakhar.github.io/project/meningioma/results-1.png&#34; /&gt;&lt;/img&gt;&lt;/p&gt;
&lt;p&gt;The confusion matrix, calculated as a normalized sum of the confusion matrices for each k-fold, can be seen below. Of the meningiomas with an actual label of zero, the model correctly labeled 17%, while incorrectly labeling 34% and 47% as one and two, respectively. Of the meningiomas with an actual label of three, the model correctly labeled 12%, while incorrectly labeling 18% and 65% as one and two, respectively.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://arsakhar.github.io/project/meningioma/results-2.png&#34; /&gt;&lt;/img&gt;&lt;/p&gt;


&lt;/div&gt;










&lt;div class=&#34;tab-pane fade&#34; id=&#34;tab16&#34; role=&#34;tabpanel&#34; aria-labelledby=&#34;nav-tabName6&#34;&gt;

	&lt;h4 id=&#34;discussion&#34;&gt;Discussion&lt;/h4&gt;
&lt;p&gt;Overall, the CNN was unable to classify Meningioma’s with high accuracy and generalized very poorly to unseen validation data. The highest validation accuracy across the training folds was only 35% which is marginally better than 25% due to random guessing. The poor validation accuracy was seen for multiple combinations of hyperparameters decreasing the likelihood that the results were due to a poorly optimized model.&lt;/p&gt;
&lt;p&gt;Poor model performance may be due a lack of discernible patterns between classes of meningioma observed on an MRI. Indeed, it is possible that the biological properties underlying the tactile hardness, texture, and consistency differences observed by the expert rater during grading are not detectable on an MRI. It is also possible that inter-rater and intra-rater variability resulted in misclassification of some meningioma’s during labeling. This variability could affect model training as the labels are not representative of the actual ground truth.&lt;/p&gt;
&lt;p&gt;Despite the poor overall accuracy, the model was able to discriminate between the extreme classes, zero and three, relatively well. As seen in the confusion matrix, the model rarely assigned class three to class zero and vice versa. Taken together, this suggests that there may be a detectable pattern between classes.&lt;/p&gt;
&lt;h4 id=&#34;future-directions&#34;&gt;Future Directions&lt;/h4&gt;
&lt;p&gt;Due to computational requirements, the grid search for the optimal hyperparameters was only run for 3 iterations. Furthermore, only the ResNet 152 CNN was trained. Training additional CNN’s and continuing the grid search over 10-15 iterations may yield a trained model better suited for the provided dataset. Different data augmentation techniques may also improve model training as well. However, these changes will likely only result in a marginal improvement in classification accuracy. To evaluate whether Meningioma’s acquired by MRI can be classified with high accuracy, additional training data is needed.&lt;/p&gt;
&lt;p&gt;In the absence of additional training data, one possibility is to run an unsupervised machine learning technique such as k-means clustering over a range of clusters. A scree plot or silhouette analysis can then be used to identify the optimal number of clusters. The labels of the images in each cluster can then be compared to identify the purity of the cluster. If the optimal number of clusters is 4, it would suggest there is a detectable pattern aligned with the expected number of classes. Moreover, if the incorrectly labeled images in each cluster are better suited for the nearest neighboring cluster. it may suggest that inter-rater and intra-rater variability are contributing to problems with model training.&lt;/p&gt;


&lt;/div&gt;










&lt;div class=&#34;tab-pane fade&#34; id=&#34;tab17&#34; role=&#34;tabpanel&#34; aria-labelledby=&#34;nav-tabName7&#34;&gt;

	&lt;h5 id=&#34;references&#34;&gt;References&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;Shiroishi, Mark S., et al. &amp;ldquo;Predicting meningioma consistency on preoperative neuroimaging studies.&amp;rdquo; Neurosurgery Clinics 27.2 (2016): 145-154.&lt;/li&gt;
&lt;li&gt;Zada, Gabriel, et al. &amp;ldquo;A proposed grading system for standardizing tumor consistency of intracranial meningiomas.&amp;rdquo; Neurosurgical focus 35.6 (2013): E1.&lt;/li&gt;
&lt;/ol&gt;


&lt;/div&gt;










&lt;div class=&#34;tab-pane fade&#34; id=&#34;tab18&#34; role=&#34;tabpanel&#34; aria-labelledby=&#34;nav-tabName8&#34;&gt;

	&lt;h4 id=&#34;technical-skills&#34;&gt;Technical Skills&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;Pre-processing MRI data&lt;/li&gt;
&lt;li&gt;Manipulating and training a convolutional neural network for image classification&lt;/li&gt;
&lt;li&gt;Cross-validation for small datasets&lt;/li&gt;
&lt;li&gt;Generating classification reports and confusion matrices&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;packages&#34;&gt;Packages&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;Optuna&lt;/li&gt;
&lt;li&gt;NiBabel&lt;/li&gt;
&lt;li&gt;Pandas&lt;/li&gt;
&lt;li&gt;NumPy&lt;/li&gt;
&lt;li&gt;Torch&lt;/li&gt;
&lt;li&gt;Torchvision&lt;/li&gt;
&lt;li&gt;Scikit-learn&lt;/li&gt;
&lt;li&gt;TorchIO&lt;/li&gt;
&lt;/ol&gt;


&lt;/div&gt;





		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

</description>
    </item>
    
    <item>
      <title>Stylet locking mechanism for medical delivery devices</title>
      <link>https://arsakhar.github.io/publication/us-patent/</link>
      <pubDate>Tue, 14 Feb 2012 23:33:39 -0700</pubDate>
      <guid>https://arsakhar.github.io/publication/us-patent/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Brain Imaging</title>
      <link>https://arsakhar.github.io/brain-imaging/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://arsakhar.github.io/brain-imaging/</guid>
      <description>&lt;div class=&#34;article-container-nav&#34;&gt;

	&lt;nav&gt;
	
		&lt;div class=&#34;sticky-scroll navtab-position nav flex-row nav-pills&#34; id=&#34;nav-tab&#34; role=&#34;tablist&#34;&gt;
			&lt;br&gt;
			
			

			
			
			

			

			&lt;a class=&#34;nav-item nav-link active&#34; id=&#34;nav-2&#34; data-toggle=&#34;tab&#34; href=&#34;#tab21&#34; role=&#34;tab&#34;
				 aria-controls=&#34;nav-home&#34; aria-selected=&#34;true&#34;&gt;Software&lt;/a&gt;

			
			

			
			
			

			

			&lt;a class=&#34;nav-item nav-link&#34; id=&#34;nav-2&#34; data-toggle=&#34;tab&#34; href=&#34;#tab22&#34; role=&#34;tab&#34;
				 aria-controls=&#34;nav-home&#34; aria-selected=&#34;false&#34;&gt;Pipelines&lt;/a&gt;

			
			
		&lt;/div&gt;
	&lt;/nav&gt;

	&lt;div class=&#34;article-style &#34;&gt;
		&lt;div class=&#34;tab-content&#34; id=&#34;2&#34;&gt;
			








&lt;div class=&#34;tab-pane fade show active&#34; id=&#34;tab21&#34; role=&#34;tabpanel&#34; aria-labelledby=&#34;nav-tabName1&#34;&gt;

	&lt;br&gt;
&lt;b&gt;&lt;u&gt;NeuroFlow&lt;/u&gt;&lt;/b&gt;&lt;br&gt;
A brain imaging tool for analyzing cerebral flow dynamics. (&lt;b&gt;&lt;a href=&#34;https://arsakhar.github.io/project/neuroflow/&#34;&gt;Read&lt;/a&gt;&lt;/b&gt;)
&lt;p&gt;&lt;a href=&#34;https://arsakhar.github.io/project/neuroflow/&#34;&gt;&lt;img src=&#34;https://arsakhar.github.io/project/neuroflow/featured.png&#34; /&gt;&lt;/img&gt;&lt;/a&gt;

&lt;/div&gt;










&lt;div class=&#34;tab-pane fade&#34; id=&#34;tab22&#34; role=&#34;tabpanel&#34; aria-labelledby=&#34;nav-tabName2&#34;&gt;

	&lt;br&gt;
The following are brain imaging pipelines I have used extensively as part of my research on aging and AD dementia. As a result, I have a strong background in visualizing, processing, and analyzing a number of different MRI modalities. This includes assessing brain morphometry on T1 and T2 images, as well as flow on PC-MRI images.
&lt;p&gt;&lt;br&gt;&lt;br&gt;
&lt;b&gt;&lt;u&gt;Hippocampal Subfields&lt;/u&gt;&lt;/b&gt;&lt;br&gt;
&lt;a href=&#34;https://www.nitrc.org/projects/ashs&#34;&gt;ASHS&lt;/a&gt; (external) is a tool for segmenting and labeling the hippocampal subfields and medial temporal lobe (MTL). The software uses T1 and T2 weighted MRI’s to segment the MTL and hippocampal subfields.&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Purpose: &lt;/b&gt; The entorhinal cortex, CA1, and CA4/dentate gyrus subfields of the hippocampus have been linked to aging and AD pathology and have also been shown to be important for spatial memory (Yushkevich PA., et al., 2014).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://arsakhar.github.io/brain-imaging/images/hippocampal_subfields.png&#34; /&gt;&lt;/img&gt;&lt;/p&gt;
&lt;br&gt;
&lt;b&gt;&lt;u&gt;General Brain Morphometry&lt;/u&gt;&lt;/b&gt;&lt;br&gt;
&lt;a href=&#34;https://surfer.nmr.mgh.harvard.edu/&#34;&gt;Freesurfer&lt;/a&gt; (external) is an open source software suite for processing and analyzing human brain MRI images. The software uses T1 MPRAGE images to segment the brain.&lt;br&gt;&lt;br&gt;
&lt;p&gt;&lt;b&gt;Purpose: &lt;/b&gt; Studies have shown that whole brain volumes decrease approximately .45% per year in older adults (Fotenos Anthony F., et al., 2005).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://arsakhar.github.io/brain-imaging/images/freesurfer_segmentation.png&#34; /&gt;&lt;/img&gt;&lt;/p&gt;
&lt;br&gt;
&lt;b&gt;&lt;u&gt;Cerebral Flow Dynamics&lt;/u&gt;&lt;/b&gt;&lt;br&gt;
&lt;a href=&#34;https://github.com/arsakhar/NeuroFlow&#34;&gt;NeuroFlow&lt;/a&gt; (written by me) is a brain imaging tool for analyzing cerebral flow dynamics. Another, older option, is BioFlow (Balédent O, et al., 2001).&lt;br&gt;&lt;br&gt;
&lt;p&gt;&lt;b&gt;Purpose: &lt;/b&gt; The cerebral aqueduct (CA) and C2-C3 region have been shown to be sensitive to the pathological changes that occur in aging and Alzheimer’s disease (El Sankari S., et al., 2011).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://arsakhar.github.io/brain-imaging/images/flow.png&#34; /&gt;&lt;/img&gt;&lt;/p&gt;
&lt;br&gt;
&lt;b&gt;&lt;u&gt;Perivascular Spaces&lt;/u&gt;&lt;/b&gt;&lt;br&gt;
The PVS Pipeline is an in-house pipeline tool written by Dr. Farshid Sepehrband.
&lt;br&gt;&lt;br&gt;
&lt;p&gt;&lt;b&gt;Purpose: &lt;/b&gt; Perivascular space size is associated with Alzheimer&amp;rsquo;s disease (Banerjee G., et al., 2017)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://arsakhar.github.io/brain-imaging/images/pvs.png&#34; /&gt;&lt;/img&gt;&lt;/p&gt;


&lt;/div&gt;





		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

</description>
    </item>
    
    <item>
      <title>Clinical Research</title>
      <link>https://arsakhar.github.io/clinical-research/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://arsakhar.github.io/clinical-research/</guid>
      <description>&lt;div class=&#34;article-container-nav&#34;&gt;

	&lt;nav&gt;
	
		&lt;div class=&#34;sticky-scroll navtab-position nav flex-row nav-pills&#34; id=&#34;nav-tab&#34; role=&#34;tablist&#34;&gt;
			&lt;br&gt;
			
			

			
			
			

			

			&lt;a class=&#34;nav-item nav-link active&#34; id=&#34;nav-1&#34; data-toggle=&#34;tab&#34; href=&#34;#tab11&#34; role=&#34;tab&#34;
				 aria-controls=&#34;nav-home&#34; aria-selected=&#34;true&#34;&gt;Software&lt;/a&gt;

			
			
		&lt;/div&gt;
	&lt;/nav&gt;

	&lt;div class=&#34;article-style &#34;&gt;
		&lt;div class=&#34;tab-content&#34; id=&#34;1&#34;&gt;
			








&lt;div class=&#34;tab-pane fade show active&#34; id=&#34;tab11&#34; role=&#34;tabpanel&#34; aria-labelledby=&#34;nav-tabName1&#34;&gt;

	&lt;br&gt;
&lt;b&gt;&lt;u&gt;FitViz&lt;/u&gt;&lt;/b&gt;&lt;br&gt;
ANT+ Health and Fitness Monitoring Client. (&lt;b&gt;&lt;a href=&#34;https://arsakhar.github.io/project/fitviz/&#34;&gt;Read&lt;/a&gt;&lt;/b&gt;)
&lt;p&gt;&lt;a href=&#34;https://arsakhar.github.io/project/fitviz/&#34;&gt;&lt;img src=&#34;https://arsakhar.github.io/project/fitviz/featured.PNG&#34; /&gt;&lt;/img&gt;&lt;/a&gt;

&lt;/div&gt;





		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

</description>
    </item>
    
    <item>
      <title>Data Science</title>
      <link>https://arsakhar.github.io/data-science/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://arsakhar.github.io/data-science/</guid>
      <description>&lt;div class=&#34;article-container-nav&#34;&gt;

	&lt;nav&gt;
	
		&lt;div class=&#34;sticky-scroll navtab-position nav flex-row nav-pills&#34; id=&#34;nav-tab&#34; role=&#34;tablist&#34;&gt;
			&lt;br&gt;
			
			

			
			
			

			

			&lt;a class=&#34;nav-item nav-link active&#34; id=&#34;nav-1&#34; data-toggle=&#34;tab&#34; href=&#34;#tab11&#34; role=&#34;tab&#34;
				 aria-controls=&#34;nav-home&#34; aria-selected=&#34;true&#34;&gt;Machine Learning&lt;/a&gt;

			
			

			
			
			

			

			&lt;a class=&#34;nav-item nav-link&#34; id=&#34;nav-1&#34; data-toggle=&#34;tab&#34; href=&#34;#tab12&#34; role=&#34;tab&#34;
				 aria-controls=&#34;nav-home&#34; aria-selected=&#34;false&#34;&gt;Data Science&lt;/a&gt;

			
			
		&lt;/div&gt;
	&lt;/nav&gt;

	&lt;div class=&#34;article-style &#34;&gt;
		&lt;div class=&#34;tab-content&#34; id=&#34;1&#34;&gt;
			








&lt;div class=&#34;tab-pane fade show active&#34; id=&#34;tab11&#34; role=&#34;tabpanel&#34; aria-labelledby=&#34;nav-tabName1&#34;&gt;

	&lt;br&gt;
&lt;b&gt;&lt;u&gt;Meningioma Classification using Machine Learning&lt;/u&gt;&lt;/b&gt;&lt;br&gt;
Using machine learning to predict Meningioma consistency. (&lt;b&gt;&lt;a href=&#34;https://arsakhar.github.io/project/meningioma/&#34;&gt;Read&lt;/a&gt;&lt;/b&gt;)
&lt;p&gt;&lt;a href=&#34;https://arsakhar.github.io/project/meningioma/&#34;&gt;&lt;img src=&#34;https://arsakhar.github.io/project/meningioma/featured.png&#34; /&gt;&lt;/img&gt;&lt;/a&gt;&lt;/p&gt;
&lt;figcaption&gt;Photo Credit: Basaia, Silvia, et al. NeuroImage: Clinical 21 (2019)&lt;/figcaption&gt;


&lt;/div&gt;











&lt;div class=&#34;tab-pane fade&#34; id=&#34;tab12&#34; role=&#34;tabpanel&#34; aria-labelledby=&#34;nav-tabName2&#34;&gt;

	&lt;br&gt;
&lt;b&gt;&lt;u&gt;Ranking College Football Coaches&lt;/u&gt;&lt;/b&gt;&lt;br&gt;
Using data science to evaluate recruiting and player development in college football. (&lt;b&gt;&lt;a href=&#34;https://arsakhar.github.io/project/ncaaf-coaches/&#34;&gt;Read&lt;/a&gt;&lt;/b&gt;)
&lt;p&gt;&lt;a href=&#34;https://arsakhar.github.io/project/ncaaf-coaches/&#34;&gt;&lt;img src=&#34;https://arsakhar.github.io/project/ncaaf-coaches/featured.png&#34; /&gt;&lt;/img&gt;&lt;/a&gt;

&lt;/div&gt;





		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

</description>
    </item>
    
    <item>
      <title>Virtual Reality</title>
      <link>https://arsakhar.github.io/virtual-reality/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://arsakhar.github.io/virtual-reality/</guid>
      <description>&lt;div class=&#34;article-container-nav&#34;&gt;

	&lt;nav&gt;
	
		&lt;div class=&#34;sticky-scroll navtab-position nav flex-row nav-pills&#34; id=&#34;nav-tab&#34; role=&#34;tablist&#34;&gt;
			&lt;br&gt;
			
			

			
			
			

			

			&lt;a class=&#34;nav-item nav-link active&#34; id=&#34;nav-1&#34; data-toggle=&#34;tab&#34; href=&#34;#tab11&#34; role=&#34;tab&#34;
				 aria-controls=&#34;nav-home&#34; aria-selected=&#34;true&#34;&gt;Inspiration&lt;/a&gt;

			
			

			
			
			

			

			&lt;a class=&#34;nav-item nav-link&#34; id=&#34;nav-1&#34; data-toggle=&#34;tab&#34; href=&#34;#tab12&#34; role=&#34;tab&#34;
				 aria-controls=&#34;nav-home&#34; aria-selected=&#34;false&#34;&gt;Games&lt;/a&gt;

			
			

			
			
			

			

			&lt;a class=&#34;nav-item nav-link&#34; id=&#34;nav-1&#34; data-toggle=&#34;tab&#34; href=&#34;#tab13&#34; role=&#34;tab&#34;
				 aria-controls=&#34;nav-home&#34; aria-selected=&#34;false&#34;&gt;Bike&lt;/a&gt;

			
			

			
			
			

			

			&lt;a class=&#34;nav-item nav-link&#34; id=&#34;nav-1&#34; data-toggle=&#34;tab&#34; href=&#34;#tab14&#34; role=&#34;tab&#34;
				 aria-controls=&#34;nav-home&#34; aria-selected=&#34;false&#34;&gt;Responsibilities&lt;/a&gt;

			
			

			
			
			

			

			&lt;a class=&#34;nav-item nav-link&#34; id=&#34;nav-1&#34; data-toggle=&#34;tab&#34; href=&#34;#tab15&#34; role=&#34;tab&#34;
				 aria-controls=&#34;nav-home&#34; aria-selected=&#34;false&#34;&gt;Skills&lt;/a&gt;

			
			

			
			
			

			

			&lt;a class=&#34;nav-item nav-link&#34; id=&#34;nav-1&#34; data-toggle=&#34;tab&#34; href=&#34;#tab16&#34; role=&#34;tab&#34;
				 aria-controls=&#34;nav-home&#34; aria-selected=&#34;false&#34;&gt;News Coverage&lt;/a&gt;

			
			
		&lt;/div&gt;
	&lt;/nav&gt;

	&lt;div class=&#34;article-style &#34;&gt;
		&lt;div class=&#34;tab-content&#34; id=&#34;1&#34;&gt;
			








&lt;div class=&#34;tab-pane fade show active&#34; id=&#34;tab11&#34; role=&#34;tabpanel&#34; aria-labelledby=&#34;nav-tabName1&#34;&gt;

	&lt;h3 id=&#34;binspirationb&#34;&gt;&lt;b&gt;Inspiration&lt;/b&gt;&lt;/h3&gt;
&lt;p&gt;Alzheimer disease is the leading cause of dementia in older adults. To date, there are no effective disease-modifying treatments, but recent studies have shown exercise and cognitive stimulation to be
associated with a reduced risk of dementia. Virtual reality is a promising technology for combining exercise and cognitive stimulation and may enhance brain health in older adults at risk for Alzheimer&amp;rsquo;s disease.

&lt;/div&gt;











&lt;div class=&#34;tab-pane fade&#34; id=&#34;tab12&#34; role=&#34;tabpanel&#34; aria-labelledby=&#34;nav-tabName2&#34;&gt;

	&lt;h3 id=&#34;bgamesb&#34;&gt;&lt;b&gt;Games&lt;/b&gt;&lt;/h3&gt;
&lt;p&gt;Sal&amp;rsquo;s Sanctuary and Wildlife Enclosure are two fun, engaging, and cognitively challenging virtual reality exergames designed specifically for older adults. A third game, Underwater Adventures is currently in development.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://arsakhar.github.io/project/sals-sanctuary/&#34;&gt;Sal&amp;rsquo;s Sanctuary&lt;/a&gt; - Rescue animals that have escaped the sanctuary while navigating an urban environment&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://arsakhar.github.io/project/wildlife-enclosure/&#34;&gt;Wildlife Enclosure&lt;/a&gt; - Look after and take care of rescued animals located in exotic environments&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://arsakhar.github.io/project/underwater-adventures/&#34;&gt;Underwater Adventures (In Development)&lt;/a&gt; - Explore and photograph aquatic life in this underwater world&lt;/p&gt;


&lt;/div&gt;










&lt;div class=&#34;tab-pane fade&#34; id=&#34;tab13&#34; role=&#34;tabpanel&#34; aria-labelledby=&#34;nav-tabName3&#34;&gt;

	&lt;h3 id=&#34;bbikeb&#34;&gt;&lt;b&gt;Bike&lt;/b&gt;&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://arsakhar.github.io/project/vr-bike/&#34;&gt;NeuroRiderVR&lt;/a&gt; - A novel, custom-built exercise bike designed specifically for older adults and locomotion in VR.

&lt;/div&gt;











&lt;div class=&#34;tab-pane fade&#34; id=&#34;tab14&#34; role=&#34;tabpanel&#34; aria-labelledby=&#34;nav-tabName4&#34;&gt;

	&lt;h3 id=&#34;bresponsibilitiesb&#34;&gt;&lt;b&gt;Responsibilities&lt;/b&gt;&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;Developed a cognitively challenging exergame in virtual reality for older adults &lt;b&gt;(Lead Engineer)&lt;/b&gt;&lt;/li&gt;
  &lt;li&gt;Developed a custom-built exercise bike &lt;b&gt;(Lead Engineer)&lt;/b&gt;&lt;/li&gt;
  &lt;li&gt;Developed the environments, physics, and interaction system for the game&lt;/li&gt;
  &lt;li&gt;Collaborated with a small, high-energy team of undergraduate students, master students, and professors&lt;/li&gt;
  &lt;li&gt;Optimized performance by utilizing assets and other techniques to reduce rendering overhead in virtual reality&lt;/li&gt;
  &lt;li&gt;Integrated a heart rate monitor into to the game for monitoring a users heart rate and heart rate variability&lt;/li&gt;
  &lt;li&gt;Integrated a custom-built exercise bike as an input controller for biking in the game&lt;/li&gt;
  &lt;li&gt;Designed and developed a SQL database to store game data&lt;/li&gt;
  &lt;li&gt;Designed and developed a login and registration system to manage a user’s session&lt;/li&gt;
  &lt;li&gt;Installed and maintained a version control server&lt;/li&gt;
&lt;/ol&gt;


&lt;/div&gt;











&lt;div class=&#34;tab-pane fade&#34; id=&#34;tab15&#34; role=&#34;tabpanel&#34; aria-labelledby=&#34;nav-tabName5&#34;&gt;

	&lt;h3 id=&#34;bsoft-skillsb&#34;&gt;&lt;b&gt;Soft Skills&lt;/b&gt;&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Leading small teams on large-scale, long-term projects&lt;/li&gt;
&lt;li&gt;Collaborating and communicating effectively on cross-functional, multi-disciplinary teams&lt;/li&gt;
&lt;li&gt;Adapting to a rapidly changing work environment&lt;/li&gt;
&lt;li&gt;Developing creative solutions to challenging problems&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;btechnical-skillsb&#34;&gt;&lt;b&gt;Technical Skills&lt;/b&gt;&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Developing serious games for virtual reality&lt;/li&gt;
&lt;li&gt;Creating 3D CAD parts and assemblies In SolidWorks&lt;/li&gt;
&lt;li&gt;Designing for manufacturing and working with the machine shop&lt;/li&gt;
&lt;li&gt;Designing and soldering circuits&lt;/li&gt;
&lt;li&gt;Designing levels, game physics and interaction systems in Unity 3D&lt;/li&gt;
&lt;li&gt;Working with assets, scripts, prefabs, textures, animation, GUI, events, and scriptable objects in Unity3D&lt;/li&gt;
&lt;li&gt;Familiarity with design patterns and interfaces&lt;/li&gt;
&lt;li&gt;Writing clean, readable, and easily maintainable code&lt;/li&gt;
&lt;li&gt;Creating and maintaining a version control server&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;bsoftwareb&#34;&gt;&lt;b&gt;Software&lt;/b&gt;&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Perforce&lt;/li&gt;
&lt;li&gt;SolidWorks&lt;/li&gt;
&lt;li&gt;Unity3D&lt;/li&gt;
&lt;li&gt;Visual Studio&lt;/li&gt;
&lt;li&gt;XAMPP&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;bprogramming-languagesb&#34;&gt;&lt;b&gt;Programming Languages&lt;/b&gt;&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;C#&lt;/li&gt;
&lt;li&gt;PHP&lt;/li&gt;
&lt;li&gt;SQL&lt;/li&gt;
&lt;li&gt;C/C++ (Arduino)&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;bpackagesb&#34;&gt;&lt;b&gt;Packages&lt;/b&gt;&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;UnityEngine.Networking – HTTP communication with web server&lt;/li&gt;
&lt;li&gt;UnityEngine.UI&lt;/li&gt;
&lt;li&gt;System.Linq&lt;/li&gt;
&lt;li&gt;System.Net.Sockets – Udp communication&lt;/li&gt;
&lt;li&gt;System.Threading&lt;/li&gt;
&lt;li&gt;System.IO.Ports – serial port communication&lt;/li&gt;
&lt;li&gt;UnityEngine&lt;/li&gt;
&lt;li&gt;UnityEngine.AI - pathfinding&lt;/li&gt;
&lt;li&gt;stdlib.h - standard Arduino library&lt;/li&gt;
&lt;li&gt;ResponsiveAnalogRead.h - analog input noise reduction&lt;/li&gt;
&lt;/ol&gt;


&lt;/div&gt;











&lt;div class=&#34;tab-pane fade&#34; id=&#34;tab16&#34; role=&#34;tabpanel&#34; aria-labelledby=&#34;nav-tabName6&#34;&gt;

	&lt;h3 id=&#34;bnews-coverageb&#34;&gt;&lt;b&gt;News Coverage&lt;/b&gt;&lt;/h3&gt;
&lt;p&gt;&lt;b&gt;Morning Joe&lt;/b&gt;&lt;/p&gt;
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/HF0HMJgy9Q8&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;
&lt;b&gt;Voice of America&lt;/b&gt;&lt;/p&gt;
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/mMD8P0ECvd0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;
&lt;a href=&#34;https://www.voanews.com/science-health/scientists-study-whether-virtual-reality-can-prevent-cognitive-decline-dementia&#34;&gt;https://www.voanews.com/science-health/scientists-study-whether-virtual-reality-can-prevent-cognitive-decline-dementia&lt;/a&gt;&lt;/p&gt;


&lt;/div&gt;





		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

</description>
    </item>
    
  </channel>
</rss>
